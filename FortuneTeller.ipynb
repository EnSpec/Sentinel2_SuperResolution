{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7689fda",
   "metadata": {},
   "source": [
    "This notebook is built to use the trained RCCN models to predict images at 2.5m resolution. You will need to run this notebook twice -- once to predict the 10m bands, and once to predict the 20m bands (ensure you ONLY run the block you want to predict below; block 4 or 5).\n",
    "\n",
    "Only blocks 2 and 3 will need to be edited by the user to provide the necessary inputs (and possibly block 8).\n",
    "\n",
    "I had to restart the kernel after each run. This is why the prediction of both wasn't built into a single notebook run. I've tried to be as efficent with the memory as possible, but depending on your RAM, you may still have problem (dev'd with an NVIDIA Corporation TU104BM [GeForce RTX 2080 Mobile], Intel® Core™ i7-9700K CPU @ 3.60GHz × 8; 32GB RAM)\n",
    "\n",
    "Near the bottome, there is an option to look at the resulting image before writing it to a file. Its commented out right now, but the first time you use this, I recommend using this to check your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23695b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,MaxPool2D ,Convolution2D , Add, Dense , AveragePooling2D , UpSampling2D , Reshape , Flatten , Subtract , Concatenate, Cropping2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "os.chdir('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This date (or file identifier) should match what was used in BeautySchoolDropout\n",
    "date = '17Jun21_'\n",
    "\n",
    "# These two files correspond to the Pyrite output.  Choose the files with the EXACT SAME ratio (10 and 20)\n",
    "s210m_10_fn = \"T16TCR_20210617T164839_10_stack_norm.tif\"  # bands\n",
    "s220m_20_fn = \"T16TCR_20210617T164839_20_stack_norm.tif\" # bands\n",
    "\n",
    "# If you gave the same identifier above as used in BeautySchoolDropout, this should run without further change\n",
    "dove10_fn = \"%sDove_mosaic.tif\" %date # 4 bands + mask\n",
    "dove10orb_fn = \"%sDove_Orbits.tif\" %date  # orbit(strip number)\n",
    "\n",
    "s210m_10_org = rasterio.open(s210m_10_fn).read().T\n",
    "s220m_20_org = rasterio.open(s220m_20_fn).read().T\n",
    "dove_img = rasterio.open(dove10_fn) # This will be used to build the profile for the resulting image\n",
    "dove10_org = dove_img.read().T\n",
    "dove10_orbits_org = rasterio.open(dove10orb_fn).read().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN TO PREDICT 10m BANDS ######\n",
    "trained_model = 'finals/%s_trained_10m_model' %date # Filepath of trained model\n",
    "image_result_out_fp = '%sDove_10mBands_predict.tif' %date # File name for resulting predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN TO PREDICT 20m BANDS ######\n",
    "trained_model = 'finals/%s_trained_20m_model' %date# Folder with  trained model\n",
    "image_result_out_fp = '%sDove_20mBands_predict.tif' %date # File name for resulting predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the profile for use later\n",
    "profile = dove_img.profile\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d00b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = ku.to_categorical(dove10_orbits_org, dtype='uint16')\n",
    "print(encoded.shape)\n",
    "\n",
    "dove10_with_orb_org = np.concatenate((dove10_org, encoded),axis=-1)\n",
    "print(dove10_with_orb_org.shape)\n",
    "\n",
    "encoded=None\n",
    "dove10_org = None\n",
    "dove_orbits_org = None\n",
    "dove_img = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46619144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for shape symetry and pad with zeros as needed\n",
    "model_images = [s210m_10_org, s220m_20_org, dove10_with_orb_org]\n",
    "\n",
    "for num, img in enumerate(model_images):   \n",
    "    print('Checking image ', num+1)    \n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        if img.shape[0] - img.shape[1] <= 3 and img.shape[0] - img.shape[1] > 0:\n",
    "            factor = img.shape[0] - img.shape[1]\n",
    "            print('%s more pixels in height' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, 0), (0, factor), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "        elif img.shape[1] - img.shape[0] <= 3 and img.shape[1] - img.shape[0] > 0:\n",
    "            factor = img.shape[1] - img.shape[0]        \n",
    "            print('%s more pixels in width' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, factor), (0, 0), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "    else:\n",
    "        print('Shape is good: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for compatibility among images\n",
    "mod_res_compare_size = model_images[0].shape[0]*4\n",
    "\n",
    "# Sometimes the above restriction causes problems.  The below line can be used to manual set the value.\n",
    "#mod_res_compare_size = 16000\n",
    "\n",
    "if model_images[2].shape[0] < mod_res_compare_size:\n",
    "    print('Fixing size compatibility. ')\n",
    "    diff = mod_res_compare_size - model_images[2].shape[0]\n",
    "    if diff < 5:\n",
    "        model_images[2] = np.pad(model_images[2], ((0, 0), (0, diff), (0, 0)))\n",
    "        model_images[2] = np.pad(model_images[2], ((0, diff), (0, 0), (0, 0)))\n",
    "        print('Padded with zeros. New shape: ', model_images[2].shape)\n",
    "    else:\n",
    "        print('Image size compatibility error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ef8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign variables\n",
    "s210m_40_org = model_images[0]\n",
    "s220m_80_org = model_images[1]\n",
    "dove10_with_orb_org = model_images[2]\n",
    "\n",
    "model_images = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shLoss(y_true, y_pred, delta=2.0):\n",
    "    diff = y_true-y_pred\n",
    "    dsq = tf.keras.backend.square(delta)\n",
    "    return tf.keras.backend.mean( dsq * (tf.sqrt(1+ tf.square(diff)/dsq)-1), axis=-1)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "        return 10* k.log(255**2 /(k.mean(k.square(y_pred - y_true))))\n",
    "\n",
    "\n",
    "class SRResnet:\n",
    "    def L1_loss(self , y_true , y_pred):\n",
    "        return k.mean(k.abs(y_true - y_pred))\n",
    "    \n",
    "    def RDBlocks(self, x, name, count = 6, filter_count=32, RDB_feat=64):\n",
    "        ## 6 layers of RDB block\n",
    "        ## this thing need to be in a damn loop for more customisability\n",
    "        li = [x]\n",
    "        pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu' , name = name+'_conv1')(x)\n",
    "\n",
    "        for i in range(2 , count+1):\n",
    "            li.append(pas)\n",
    "            out =  Concatenate(axis = -1)(li) # conctenated output self.channel_axis\n",
    "            pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu', name = name+'_conv'+str(i))(out)\n",
    "\n",
    "        li.append(pas)\n",
    "        out1 = Concatenate(axis = -1)(li) #self.channel_axis\n",
    "        feat = Convolution2D(filters=RDB_feat, kernel_size=(1,1), strides=(1, 1), padding='same',activation='relu' , name = name+'_Local_Conv')(out1)\n",
    "\n",
    "        feat = Add()([feat , x])\n",
    "        print(\"RDBlocks\",feat)\n",
    "        return feat\n",
    "        \n",
    "    def visualize(self):\n",
    "        plot_model(self.model, to_file='model.png' , show_shapes = True)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def Block_Of_RDBBlocks(self, inp, RDB_count=20, count=6, filter_count=32, RDB_feat=64, end_feat=64):\n",
    "        \n",
    "        pass1 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(inp)\n",
    "\n",
    "        pass2 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pass1)\n",
    "\n",
    "\n",
    "        RDB = self.RDBlocks(pass2 , 'RDB1', count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "        RDBlocks_list = [RDB,]\n",
    "        for i in range(2,RDB_count+1):\n",
    "            RDB = self.RDBlocks(RDB ,'RDB'+str(i), count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "            RDBlocks_list.append(RDB)\n",
    "        out = Concatenate(axis = -1)(RDBlocks_list) #self.channel_axis\n",
    "        out = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(out)\n",
    "        output = Add()([out, pass1])\n",
    "        output = Convolution2D(filters=end_feat, kernel_size=(3,3), strides=(1,1), padding='same', name=\"rdb_out\")(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __init__(self, s10img, s20img, psimg, lr=0.00005, patch_size=32, RDB_count=4, count=2, filter_count=64, RDB_feat=128, end_feat=128, chk = -1, scale = 4):\n",
    "        self.channel_axis = 3\n",
    "        inp10 = Input(shape = (s10img.shape[1], s10img.shape[2], s10img.shape[3]))   # (24,24,4)\n",
    "        inp20 = Input(shape = (s20img.shape[1], s20img.shape[2], s20img.shape[3]))   # (12,12,6)\n",
    "        inpPS = Input(shape = (psimg.shape[1], psimg.shape[2], psimg.shape[3]))   # (96,96,9)\n",
    "        print(psimg.shape)\n",
    "        print(s10img.shape)\n",
    "        print(s20img.shape)\n",
    "#         print(psorb.shape)\n",
    "#         ps = tf.keras.layers.Concatenate(axis=2)([psimg, psorb])\n",
    "\n",
    "        Subpixel_scale8 = Lambda(lambda x:tf.nn.depth_to_space(x,8))\n",
    "        Subpixel_scale4 = Lambda(lambda x:tf.nn.depth_to_space(x,4))\n",
    "        \n",
    "        s220c = Convolution2D(filters = (s20img.shape[3])*8*8*mlt, kernel_size=1, strides=1, padding='valid')(inp20)\n",
    "        print(\"S220c shape is\", s220c.shape)\n",
    "        s220s = Subpixel_scale8(inputs=s220c)\n",
    "        print(\"S220s shape is\", s220s.shape)\n",
    "        m20 = Model(inputs=inp20, outputs=s220s)\n",
    "        s210c = Convolution2D(filters = (s10img.shape[3])*4*4*mlt, kernel_size=1, strides=1, padding='valid')(inp10)\n",
    "        print(\"S210c shape is\", s210c.shape)\n",
    "        s210s = Subpixel_scale4(inputs=s210c)\n",
    "        print(\"S210s shape is\", s210s.shape)\n",
    "        m10 = Model(inputs=inp10, outputs=s210s)\n",
    "        \n",
    "        all_inp = Concatenate(axis=-1)([m10.output, m20.output, inpPS])\n",
    "        print(\"all_inp shape is\", all_inp.shape)\n",
    "        allb = self.Block_Of_RDBBlocks(all_inp, RDB_count, count, filter_count, RDB_feat, end_feat)\n",
    "        print(\"BofRDBlocks\",allb)\n",
    "        allm = Cropping2D(cropping=16)(allb)\n",
    "        print(\"Cropping\",allm)\n",
    "        allrc = Convolution2D(filters = 6, kernel_size = 1, strides = 1, padding = \"valid\", activation = None)(allm)\n",
    "        \n",
    "        print(\"Output\", allrc)\n",
    "        model = Model(inputs=[m10.input, m20.input, inpPS], outputs = allrc)\n",
    "#         print([n.input_tensors.name for n in model.get_layer('A_3').inbound_nodes])\n",
    "        adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=0, amsgrad=False)\n",
    "\n",
    "        model.compile(loss=shLoss, optimizer='adam' , metrics=['mae'])\n",
    "\n",
    "        if chk >=0 :\n",
    "            print(\"loading existing weights !!!\")\n",
    "            model.load_weights('final.h5')\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "    def fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, steps_per_epoch):   \n",
    "        hist = self.model.fit(x, y, batch_size, epochs, verbose, callbacks, validation_data=validation_data, steps_per_epoch=steps_per_epoch)\n",
    "        return hist.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e73546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_patches_orig(dset_10m, dset_20m, ps, patchSize=24, border=4, ps_patch=96, ps_border=16):\n",
    "\n",
    "    PATCH_SIZE_HR = (patchSize, patchSize)\n",
    "    PATCH_SIZE_LR = [p//2 for p in PATCH_SIZE_HR]\n",
    "    BORDER_HR = border\n",
    "    BORDER_LR = BORDER_HR//2\n",
    "    PATCH_SIZE_PS = (ps_patch, ps_patch)\n",
    "    \n",
    "\n",
    "    # Mirror the data at the borders to have the same dimensions as the input\n",
    "    dset_10 = np.pad(dset_10m, ((BORDER_HR, BORDER_HR), (BORDER_HR, BORDER_HR), (0, 0)))\n",
    "    dset_20 = np.pad(dset_20m, ((BORDER_LR, BORDER_LR), (BORDER_LR, BORDER_LR), (0, 0)))\n",
    "    dset_ps = np.pad(ps, ((ps_border, ps_border), (ps_border, ps_border), (0, 0))) \n",
    "\n",
    "    BANDS10 = dset_10.shape[2]\n",
    "    BANDS20 = dset_20.shape[2]\n",
    "    BANDSps = dset_ps.shape[2]\n",
    "    patchesAlongi = (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    patchesAlongj = (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    #nr_patches = (patchesAlongi + 1) * (patchesAlongj + 1)\n",
    "    nr_patches = patchesAlongi*patchesAlongj\n",
    "\n",
    "    image_20 = np.zeros((nr_patches, BANDS20) + tuple(PATCH_SIZE_LR)).astype(np.float32)\n",
    "    image_10 = np.zeros((nr_patches, BANDS10) + PATCH_SIZE_HR).astype(np.float32)\n",
    "    image_ps = np.zeros((nr_patches, BANDSps) + PATCH_SIZE_PS).astype(np.float32)\n",
    "\n",
    "    range_i = np.arange(0, (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    range_j = np.arange(0, (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    if not (np.mod(dset_20.shape[0] - 2 * BORDER_LR, PATCH_SIZE_LR[0] - 2 * BORDER_LR) == 0):\n",
    "        range_i = np.append(range_i, (dset_20.shape[0] - PATCH_SIZE_LR[0]))\n",
    "    if not (np.mod(dset_20.shape[1] - 2 * BORDER_LR, PATCH_SIZE_LR[1] - 2 * BORDER_LR) == 0):\n",
    "        range_j = np.append(range_j, (dset_20.shape[1] - PATCH_SIZE_LR[1]))\n",
    "\n",
    "    pCount = 0\n",
    "    for ii in range_i.astype(int):\n",
    "        for jj in range_j.astype(int):\n",
    "            upper_left_i = ii\n",
    "            upper_left_j = jj\n",
    "            crop_point_lr = [upper_left_i,\n",
    "                             upper_left_j,\n",
    "                             upper_left_i + PATCH_SIZE_LR[0],\n",
    "                             upper_left_j + PATCH_SIZE_LR[1]]\n",
    "            crop_point_hr = [p*2 for p in crop_point_lr]\n",
    "            crop_point_ps = [p*4 for p in crop_point_hr]\n",
    "            \n",
    "            image_20[pCount] = np.rollaxis(dset_20[crop_point_lr[0]:crop_point_lr[2],\n",
    "                             crop_point_lr[1]:crop_point_lr[3]], 2)\n",
    "            \n",
    "            image_10[pCount] = np.rollaxis(dset_10[crop_point_hr[0]:crop_point_hr[2],\n",
    "                             crop_point_hr[1]:crop_point_hr[3]], 2)\n",
    "            \n",
    "            image_ps[pCount] = np.rollaxis(dset_ps[crop_point_ps[0]:crop_point_ps[2],\n",
    "                             crop_point_ps[1]:crop_point_ps[3]], 2)\n",
    "            pCount += 1\n",
    "\n",
    "    return image_10, image_20, image_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a69456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break up the image into bite-sized chucks for memory\n",
    "print('All calculations for Dove imagery.')\n",
    "print(dove10_with_orb_org.shape)\n",
    "\n",
    "div_factor = 50\n",
    "\n",
    "# Width\n",
    "w_int_64 = int(dove10_with_orb_org.shape[1] / 64)\n",
    "print('Number of pixel blocks for this image (as integer): %s pixels (width) / 64 pixels =' %dove10_with_orb_org.shape[0], w_int_64)\n",
    "\n",
    "piece_size_ps = div_factor*64  # Size of ps chunk, multiple of 64\n",
    "print('Height and width of one square pixel block: %s*64 = ' %div_factor + str(piece_size_ps) + ' pixels')\n",
    "\n",
    "num_of_pieces = int(w_int_64 / div_factor)\n",
    "print('Number of pieces per row (one piece = 10 pixel blocks): pixel blocks / %s =' %div_factor, num_of_pieces)\n",
    "\n",
    "print('Resulting number of pixels per row to be predicted (64 * %s * number of pieces): ' %div_factor, num_of_pieces*64*div_factor)\n",
    "\n",
    "# Height = Number of rows to process\n",
    "num_of_rows = int(dove10_with_orb_org.shape[0] / piece_size_ps)\n",
    "print('Number of rows (rounded integer): Image Height (%s) / Piece height (%s) = ' %(dove10_with_orb_org.shape[0],piece_size_ps), num_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a436a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate the S2 imagery\n",
    "piece_size_10m = int(piece_size_ps/4) # Size of S2 10m chunk  \n",
    "piece_size_20m = int(piece_size_10m/2) # Size of S2 20m chunk  \n",
    "print('Dove block size:  ', piece_size_ps)\n",
    "print('S2 10m block size: ', piece_size_10m)\n",
    "print('S2 20m block size: ', piece_size_20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_final20 = tf.keras.models.load_model(trained_model, custom_objects={'SRResnet': SRResnet, 'shLoss': shLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa452e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create overlap to mitigate edge effects\n",
    "for row in range(num_of_rows):\n",
    "    upper10m = piece_size_10m * row\n",
    "    lower10m = piece_size_10m * (row+1)\n",
    "    \n",
    "    upper20m = piece_size_20m * row\n",
    "    lower20m = piece_size_20m * (row+1)\n",
    "    \n",
    "    upperps = piece_size_ps * row\n",
    "    lowerps = piece_size_ps * (row+1)\n",
    "    print('Row segment %s: ' %row, upperps, lowerps)\n",
    "\n",
    "    final_image_pieces = []\n",
    "    \n",
    "    for piece in range(0, num_of_pieces):\n",
    "        print('Piece: ', piece)\n",
    "        left10m = piece_size_10m * piece\n",
    "        right10m = piece_size_10m * (piece+1)\n",
    "        #print(left10m, right10m)\n",
    "\n",
    "        left20m = piece_size_20m * piece\n",
    "        right20m = piece_size_20m * (piece+1)\n",
    "        #print(left20m, right20m)\n",
    "\n",
    "        leftps = piece_size_ps * piece\n",
    "        rightps = piece_size_ps * (piece+1)\n",
    "        #print(f'{leftps =}, {rightps =}')\n",
    "            \n",
    "        # Top left corner            \n",
    "        if row == 0 and piece == 0:\n",
    "            location = 'Top left corner'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m:lower10m+16, left10m:right10m+16, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m:lower20m+8, left20m:right20m+8, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps:lowerps+64, leftps:rightps+64, :]\n",
    "\n",
    "        # Top right corner            \n",
    "        elif row == 0 and piece == num_of_pieces-1:\n",
    "            location = 'Top right corner'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m:lower10m+16, left10m-16:right10m, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m:lower20m+8, left20m-8:right20m, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps:lowerps+64, leftps-64:rightps, :]\n",
    "        \n",
    "        # Top row\n",
    "        elif row == 0 and piece != 0 and piece != num_of_pieces-1:\n",
    "            location = 'Top row'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m:lower10m+32, left10m-16:right10m+16, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m:lower20m+16, left20m-8:right20m+8, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps:lowerps+128, leftps-64:rightps+64, :]\n",
    "    \n",
    "       # Bottom left corner   \n",
    "        elif row == num_of_rows-1 and piece == 0:  \n",
    "            location = 'Bottom left corner'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-16:lower10m, left10m:right10m+16, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-8:lower20m, left20m:right20m+8, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-64:lowerps, leftps:rightps+64, :]\n",
    "            \n",
    "        # Bottom right corner            \n",
    "        elif row == num_of_rows-1 and piece == num_of_pieces-1:\n",
    "            location = 'Bottom right corner'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-16:lower10m, left10m-16:right10m, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-8:lower20m, left20m-8:right20m, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-64:lowerps, leftps-64:rightps, :]\n",
    "            \n",
    "        # Bottom row\n",
    "        elif row == num_of_rows-1 and piece != num_of_pieces-1:\n",
    "            location = 'Bottom row'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-32:lower10m, left10m-16:right10m+16, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-16:lower20m, left20m-8:right20m+8, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-128:lowerps, leftps-64:rightps+64, :]\n",
    "            \n",
    "        # Left edge\n",
    "        elif row != 0 and row != num_of_rows-1 and piece == 0:\n",
    "            location = 'Left edge'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-16:lower10m+16, left10m:right10m+32, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-8:lower20m+8, left20m:right20m+16, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-64:lowerps+64, leftps:rightps+128, :]\n",
    "        \n",
    "        # Right edge\n",
    "        elif row != 0 and row != num_of_rows-1 and piece == num_of_pieces-1:\n",
    "            location = 'Right edge'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-16:lower10m+16, left10m-32:right10m, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-8:lower20m+8, left20m-16:right20m, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-64:lowerps+64, leftps-128:rightps, :]\n",
    "            \n",
    "        # Middle\n",
    "        else:\n",
    "            location = 'Middle'\n",
    "            print(location)\n",
    "            s210m_40 =           s210m_40_org[upper10m-16:lower10m+16, left10m-16:right10m+16, :]\n",
    "            s220m_80 =           s220m_80_org[upper20m-8:lower20m+8, left20m-8:right20m+8, :]\n",
    "            dove10_with_orb = dove10_with_orb_org[upperps-64:lowerps+64, leftps-64:rightps+64, :]\n",
    "\n",
    "        images_210, images_220, images_ps = get_test_patches_orig(s210m_40, s220m_80, dove10_with_orb)\n",
    "\n",
    "        images_210 = np.moveaxis(images_210, 1, 3)\n",
    "        images_220 = np.moveaxis(images_220, 1, 3)\n",
    "        images_ps = np.moveaxis(images_ps, 1, 3)\n",
    "\n",
    "        g = model_final20.predict([images_210, images_220, images_ps])\n",
    "\n",
    "        # Reduce size by converting back to uint16\n",
    "        g = g.astype('uint16')\n",
    "        \n",
    "        # Set up iterator to recreate image\n",
    "        patches_per_row = np.sqrt(g.shape[0]).astype('int')\n",
    "        row_length = range(0, g.shape[0]+1, patches_per_row)\n",
    "        \n",
    "        # Recreate image\n",
    "        for num, val in enumerate(row_length[:-1]):\n",
    "            a=val\n",
    "            b=row_length[num+1]\n",
    "            full_block = np.hstack(g[a:b, :, :])\n",
    "            if num==0:\n",
    "                img_block = full_block.copy()\n",
    "            else:\n",
    "                img_block = np.vstack((img_block,full_block))\n",
    "\n",
    "        if location == 'Top left corner':\n",
    "            img_block = img_block[:-64, :-64, :]\n",
    "            \n",
    "        elif location == 'Top right corner':\n",
    "            img_block = img_block[:-64, 64:, :]\n",
    "            \n",
    "        elif location == 'Top row':\n",
    "            img_block = img_block[:-128, 64:-64, :]\n",
    "            \n",
    "        elif location == 'Bottom left corner':\n",
    "            img_block = img_block[64:, :-64, :]\n",
    "            \n",
    "        elif location == 'Bottom right corner':\n",
    "            img_block = img_block[64:, 64:, :]\n",
    "            \n",
    "        elif location == 'Bottom row':\n",
    "            img_block = img_block[128:, 64:-64, :]   \n",
    "            \n",
    "        elif location == 'Left edge':\n",
    "            img_block = img_block[64:-64, :-128, :]             \n",
    "                    \n",
    "        elif location == 'Right edge':\n",
    "            img_block = img_block[64:-64, 128:, :]           \n",
    "        \n",
    "        else:\n",
    "            img_block = img_block[64:-64, 64:-64, :]\n",
    "        \n",
    "        final_image_pieces.append(img_block)\n",
    "\n",
    "        img_block = None\n",
    "        g = None\n",
    "        images_210 = None\n",
    "        images_220 = None\n",
    "        images_ps = None\n",
    "\n",
    "    img_row = np.array(final_image_pieces)\n",
    "    # Puts together the pieces in the row (portion of full image)\n",
    "    img_row = np.hstack(img_row)\n",
    "\n",
    "    if row==0:\n",
    "        full_image = img_row.copy()\n",
    "\n",
    "    elif row==num_of_rows-1:\n",
    "        # Clear memory \n",
    "        s210m_40_org = None\n",
    "        s220m_80_org = None\n",
    "        dove10_org = None\n",
    "        dove10_orbits_org = None\n",
    "        dove10_with_orb_org = None\n",
    "        tf.keras.backend.clear_session()\n",
    "        model_final20 = None\n",
    "\n",
    "        full_image = np.vstack((full_image,img_row))\n",
    "\n",
    "    else:\n",
    "        full_image = np.vstack((full_image,img_row))\n",
    "\n",
    "    img_row = None\n",
    "    final_image_pieces = None\n",
    "    s210m_40 = None\n",
    "    s220m_80 = None\n",
    "    dove_with_orb = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(full_image[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['height']=full_image.shape[0]\n",
    "profile['width']=full_image.shape[1]\n",
    "profile['count']=full_image.shape[2]\n",
    "profile['tiled']=True\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(image_result_out_fp, 'w', **profile) as dst:\n",
    "    dst.write(full_image.T)\n",
    "\n",
    "full_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970455dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
