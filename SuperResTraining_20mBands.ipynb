{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook is built to develop and train the RCCN model for the 20 m bands (NIR2, RE bands, and SWIR bands). Only blocks 2 and 3 will need to be edited by the user to provide the necessary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7kNDltfZnld"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,MaxPool2D ,Convolution2D , Add, Dense , AveragePooling2D , UpSampling2D , Reshape , Flatten , Subtract , Concatenate, Cropping2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "os.chdir('...')\n",
    "\n",
    "# Provide a folder with which to place the final model. \n",
    "# IMPORTANT: DO NOT put the same folder as the imagery.Temporary models will be stored there,\n",
    "# but then deleted. If you do not give a separate location for the complete models, they will also be deleted.\n",
    "# Ensure there is a '/' at the end.\n",
    "output_folder = \".../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1635267928824,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "44EfYevlcbCM",
    "outputId": "679fc8e2-0f44-48c3-8a91-0ee8aea7efa7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This date (or file identifier) should match what was used in BeautySchoolDropout\n",
    "date = '17Jun21_'\n",
    "\n",
    "# These two files correspond to the Pyrite output.  Choose the files with the EXACT SAME ratio (10to80, 20to160)\n",
    "s210m_80_fn = \"T16TCR_20210617T164839_10to80_stack_norm.tif\" \n",
    "s220m_160_fn = \"T16TCR_20210617T164839_20to160_stack_norm.tif\" \n",
    "\n",
    "# Ground truth. Choose the file that ends with \"20_stack_norm.tif\"\n",
    "s220m_20_fn = \"T16TCR_20210617T164839_20_stack_norm.tif\" \n",
    "\n",
    "# If you gave the same identifier above as used in BeautySchoolDropout, this should run without further change\n",
    "dove20_fn = \"%sDove_10m_mosaic.tif\" %date # 4 bands + mask\n",
    "dove20orb_fn = \"%sDove_Orbits_10m.tif\" %date # orbit(strip number)\n",
    "\n",
    "s210m_80 = rasterio.open(s210m_80_fn).read().T\n",
    "s220m_160 = rasterio.open(s220m_160_fn).read().T\n",
    "dove20 = rasterio.open(dove20_fn).read().T\n",
    "dove20_orbits = rasterio.open(dove20orb_fn).read().T\n",
    "\n",
    "print('Shape of downsampled Sentinel-2 10m array: ', s210m_80.shape)\n",
    "print('Shape of downsampled Sentinel-2 20m array: ', s220m_160.shape)\n",
    "print('Shape of downsampled Dove array: ', dove20.shape)\n",
    "print('Shape of downsampled Dove orbit array: ', dove20_orbits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s220m_20 = rasterio.open(s220m_20_fn).read().T\n",
    "s220m_20 = s220m_20[:,:, :-1].copy()  # Remove mask for model validation \n",
    "\n",
    "s220m_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = ku.to_categorical(dove20_orbits, dtype='uint16')\n",
    "print(encoded.shape)\n",
    "\n",
    "dove20_with_orb = np.concatenate((dove20, encoded),axis=-1)\n",
    "print(dove20_with_orb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1237,
     "status": "ok",
     "timestamp": 1635267932338,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "-Po_bHlNdmNJ",
    "outputId": "d05d1744-59f7-4fd5-a498-1e21ce151d8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for shape symetry and pad with zeros as needed\n",
    "model_images = [s210m_80, s220m_160, dove20_with_orb, s220m_20]\n",
    "\n",
    "for num, img in enumerate(model_images):   \n",
    "    print('Checking image ', num+1)    \n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        if img.shape[0] - img.shape[1] <= 3 and img.shape[0] - img.shape[1] > 0:\n",
    "            factor = img.shape[0] - img.shape[1]\n",
    "            print('%s more pixels in height' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, 0), (0, factor), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "        elif img.shape[1] - img.shape[0] <= 3 and img.shape[1] - img.shape[0] > 0:\n",
    "            factor = img.shape[1] - img.shape[0]        \n",
    "            print('%s more pixels in width' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, factor), (0, 0), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "    else:\n",
    "        print('Shape is good: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for compatibility among images\n",
    "mod_res_compare_size = model_images[0].shape[0]*4\n",
    "\n",
    "if model_images[2].shape[0] < mod_res_compare_size:\n",
    "    print('Fixing size compatibility. ')\n",
    "    diff = mod_res_compare_size - model_images[2].shape[0]\n",
    "    if diff < 5:\n",
    "        model_images[2] = np.pad(model_images[2], ((0, 0), (0, diff), (0, 0)))\n",
    "        model_images[2] = np.pad(model_images[2], ((0, diff), (0, 0), (0, 0)))\n",
    "        print('Padded with zeros. New shape: ', model_images[2].shape)\n",
    "    else:\n",
    "        print('Image size compatibility error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiuRB6K6eI5R"
   },
   "outputs": [],
   "source": [
    "def get_test_patches(dset_10m, dset_20m, ps, dset_20gt, patchSize=24, border=4, ps_patch=96, ps_border=16):\n",
    "\n",
    "    PATCH_SIZE_HR = (patchSize, patchSize)\n",
    "    PATCH_SIZE_LR = [p//2 for p in PATCH_SIZE_HR]\n",
    "    BORDER_HR = border\n",
    "    BORDER_LR = BORDER_HR//2\n",
    "    PATCH_SIZE_PS = (ps_patch, ps_patch)\n",
    "    PATCH_SIZE_GT = (ps_patch-2*ps_border, ps_patch-2*ps_border)\n",
    "    \n",
    "    # Mirror the data at the borders to have the same dimensions as the input\n",
    "    dset_10 = np.pad(dset_10m, ((BORDER_HR, BORDER_HR), (BORDER_HR, BORDER_HR), (0, 0)))\n",
    "    dset_20 = np.pad(dset_20m, ((BORDER_LR, BORDER_LR), (BORDER_LR, BORDER_LR), (0, 0)))\n",
    "    dset_ps = np.pad(ps, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    dset_gt = np.pad(dset_20gt, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))  \n",
    "\n",
    "    BANDS10 = dset_10.shape[2]\n",
    "    BANDS20 = dset_20.shape[2]\n",
    "    BANDSps = dset_ps.shape[2]\n",
    "    BANDSgt = dset_gt.shape[2]\n",
    "    patchesAlongi = (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    patchesAlongj = (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    nr_patches = (patchesAlongi + 1) * (patchesAlongj + 1)\n",
    "\n",
    "    label_20 = np.zeros((nr_patches, BANDSgt) + PATCH_SIZE_GT).astype(np.float32)   #initialize with PATCH_SIZE_PS but crop to PATCH_SIZE_GT\n",
    "    image_20 = np.zeros((nr_patches, BANDS20) + tuple(PATCH_SIZE_LR)).astype(np.float32)\n",
    "    image_10 = np.zeros((nr_patches, BANDS10) + PATCH_SIZE_HR).astype(np.float32)\n",
    "    image_ps = np.zeros((nr_patches, BANDSps) + PATCH_SIZE_PS).astype(np.float32)\n",
    "\n",
    "    range_i = np.arange(0, (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    range_j = np.arange(0, (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    if not (np.mod(dset_20.shape[0] - 2 * BORDER_LR, PATCH_SIZE_LR[0] - 2 * BORDER_LR) == 0):\n",
    "        range_i = np.append(range_i, (dset_20.shape[0] - PATCH_SIZE_LR[0]))\n",
    "    if not (np.mod(dset_20.shape[1] - 2 * BORDER_LR, PATCH_SIZE_LR[1] - 2 * BORDER_LR) == 0):\n",
    "        range_j = np.append(range_j, (dset_20.shape[1] - PATCH_SIZE_LR[1]))\n",
    "\n",
    "    pCount = 0\n",
    "    for ii in range_i.astype(int):\n",
    "        for jj in range_j.astype(int):\n",
    "            upper_left_i = ii\n",
    "            upper_left_j = jj\n",
    "            crop_point_lr = [upper_left_i,\n",
    "                             upper_left_j,\n",
    "                             upper_left_i + PATCH_SIZE_LR[0],\n",
    "                             upper_left_j + PATCH_SIZE_LR[1]]\n",
    "            crop_point_hr = [p*2 for p in crop_point_lr]\n",
    "            crop_point_ps = [p*4 for p in crop_point_hr]\n",
    "            crop_point_gt = [p*4 for p in crop_point_hr]\n",
    "\n",
    "            \n",
    "            label_20[pCount] = np.rollaxis(dset_gt[crop_point_gt[0]+ps_border:crop_point_gt[2]-ps_border, \n",
    "                                                crop_point_gt[1]+ps_border:crop_point_gt[3]-ps_border], 2)\n",
    "            \n",
    "            image_20[pCount] = np.rollaxis(dset_20[crop_point_lr[0]:crop_point_lr[2],\n",
    "                             crop_point_lr[1]:crop_point_lr[3]], 2)\n",
    "            \n",
    "            image_10[pCount] = np.rollaxis(dset_10[crop_point_hr[0]:crop_point_hr[2],\n",
    "                             crop_point_hr[1]:crop_point_hr[3]], 2)\n",
    "            \n",
    "            image_ps[pCount] = np.rollaxis(dset_ps[crop_point_ps[0]:crop_point_ps[2],\n",
    "                             crop_point_ps[1]:crop_point_ps[3]], 2)\n",
    "            pCount += 1\n",
    "\n",
    "    return image_10, image_20, image_ps, label_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1635268003472,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "2DclF1KceMrS",
    "outputId": "a86369a8-9f16-48ea-a616-4909a330511e"
   },
   "outputs": [],
   "source": [
    "images_210, images_220, images_ps, label_20 = get_test_patches(model_images[0], model_images[1], model_images[2], model_images[3])\n",
    "#images_210, images_220, images_ps, label_20 = get_test_patches(s210m_40, s220m_80, dove10_with_orb, s220m_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1635268005432,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "s94kbHRwePXH",
    "outputId": "54691f7f-e3ec-4a1e-f1f9-5d4dd1babf7b"
   },
   "outputs": [],
   "source": [
    "images_210 = np.moveaxis(images_210, 1, 3)\n",
    "images_220 = np.moveaxis(images_220, 1, 3)\n",
    "images_ps = np.moveaxis(images_ps, 1, 3)\n",
    "label_20 = np.moveaxis(label_20, 1, 3)\n",
    "\n",
    "print(images_210.shape)\n",
    "print(images_220.shape)\n",
    "print(images_ps.shape)\n",
    "print(label_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eokpDUcOeaQ6"
   },
   "outputs": [],
   "source": [
    "images_210_tr1, images_210_test, images_220_tr1, images_220_test, images_ps_tr1, images_ps_test, label_20_tr1, label_20_test = train_test_split(images_210, images_220, images_ps, label_20, test_size=0.1, random_state=1)\n",
    "images_210_train, images_210_val, images_220_train, images_220_val, images_ps_train, images_ps_val, label_20_train, label_20_val = train_test_split(images_210_tr1, images_220_tr1, images_ps_tr1, label_20_tr1, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7799,
     "status": "ok",
     "timestamp": 1635268025239,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "fzts5DOledmK",
    "outputId": "f4c0bdb9-659a-44c3-ab43-01772c536d1b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size1 = 32\n",
    "epochs1 = 100\n",
    "steps_per_epoch = 300\n",
    "tryout = 200\n",
    "gpu = 16 #check\n",
    "sample = 32\n",
    "mlt = 5\n",
    "scale = 8\n",
    "# patch_size = int(scale * 1024)\n",
    "patch_size = 96\n",
    "\n",
    "test_only = False\n",
    "\n",
    "chk = 1\n",
    "CHANNEL = 3\n",
    "\n",
    "def shLoss(y_true, y_pred, delta=2.0):\n",
    "    diff = y_true-y_pred\n",
    "    dsq = tf.keras.backend.square(delta)\n",
    "    return tf.keras.backend.mean( dsq * (tf.sqrt(1+ tf.square(diff)/dsq)-1), axis=-1)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "        return 10* k.log(255**2 /(k.mean(k.square(y_pred - y_true))))\n",
    "\n",
    "\n",
    "class SRResnet:\n",
    "    def L1_loss(self , y_true , y_pred):\n",
    "        return k.mean(k.abs(y_true - y_pred))\n",
    "    \n",
    "    def RDBlocks(self, x, name, count = 6, filter_count=32, RDB_feat=64):\n",
    "        ## 6 layers of RDB block\n",
    "        ## this thing need to be in a damn loop for more customisability\n",
    "        li = [x]\n",
    "        pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu' , name = name+'_conv1')(x)\n",
    "\n",
    "        for i in range(2 , count+1):\n",
    "            li.append(pas)\n",
    "            out =  Concatenate(axis = -1)(li) # conctenated output self.channel_axis\n",
    "            pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu', name = name+'_conv'+str(i))(out)\n",
    "\n",
    "        li.append(pas)\n",
    "        out1 = Concatenate(axis = -1)(li) #self.channel_axis\n",
    "        feat = Convolution2D(filters=RDB_feat, kernel_size=(1,1), strides=(1, 1), padding='same',activation='relu' , name = name+'_Local_Conv')(out1)\n",
    "\n",
    "        feat = Add()([feat , x])\n",
    "        print(\"RDBlocks\",feat)\n",
    "        return feat\n",
    "        \n",
    "    def visualize(self):\n",
    "        plot_model(self.model, to_file='model.png' , show_shapes = True)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def Block_Of_RDBBlocks(self, inp, RDB_count=20, count=6, filter_count=32, RDB_feat=64, end_feat=64):\n",
    "        \n",
    "        pass1 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(inp)\n",
    "\n",
    "        pass2 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pass1)\n",
    "\n",
    "\n",
    "        RDB = self.RDBlocks(pass2 , 'RDB1', count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "        RDBlocks_list = [RDB,]\n",
    "        for i in range(2,RDB_count+1):\n",
    "            RDB = self.RDBlocks(RDB ,'RDB'+str(i), count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "            RDBlocks_list.append(RDB)\n",
    "        out = Concatenate(axis = -1)(RDBlocks_list) #self.channel_axis\n",
    "        out = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(out)\n",
    "        output = Add()([out, pass1])\n",
    "        output = Convolution2D(filters=end_feat, kernel_size=(3,3), strides=(1,1), padding='same', name=\"rdb_out\")(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __init__(self, s10img, s20img, psimg, lr=0.00005, patch_size=32, RDB_count=4, count=2, filter_count=64, RDB_feat=128, end_feat=128, chk = -1, scale = 4):\n",
    "        self.channel_axis = 3\n",
    "        inp10 = Input(shape = (s10img.shape[1], s10img.shape[2], s10img.shape[3]))   # (24,24,4)\n",
    "        inp20 = Input(shape = (s20img.shape[1], s20img.shape[2], s20img.shape[3]))   # (12,12,6)\n",
    "        inpPS = Input(shape = (psimg.shape[1], psimg.shape[2], psimg.shape[3]))   # (96,96,9)\n",
    "\n",
    "        Subpixel_scale8 = Lambda(lambda x:tf.nn.depth_to_space(x,8))\n",
    "        Subpixel_scale4 = Lambda(lambda x:tf.nn.depth_to_space(x,4))\n",
    "        \n",
    "        s220c = Convolution2D(filters = (s20img.shape[3])*8*8*mlt, kernel_size=1, strides=1, padding='valid')(inp20)\n",
    "        print(\"S220c shape is\", s220c.shape)\n",
    "        s220s = Subpixel_scale8(inputs=s220c)\n",
    "        print(\"S220s shape is\", s220s.shape)\n",
    "        m20 = Model(inputs=inp20, outputs=s220s)\n",
    "        s210c = Convolution2D(filters = (s10img.shape[3])*4*4*mlt, kernel_size=1, strides=1, padding='valid')(inp10)\n",
    "        print(\"S210c shape is\", s210c.shape)\n",
    "        s210s = Subpixel_scale4(inputs=s210c)\n",
    "        print(\"S210s shape is\", s210s.shape)\n",
    "        m10 = Model(inputs=inp10, outputs=s210s)\n",
    "        \n",
    "        all_inp = Concatenate(axis=-1)([m10.output, m20.output, inpPS])\n",
    "        print(\"all_inp shape is\", all_inp.shape)\n",
    "        allb = self.Block_Of_RDBBlocks(all_inp, RDB_count, count, filter_count, RDB_feat, end_feat)\n",
    "        print(\"BofRDBlocks\",allb)\n",
    "        allm = Cropping2D(cropping=16)(allb)\n",
    "        print(\"Cropping\",allm)\n",
    "        allrc = Convolution2D(filters = 6, kernel_size = 1, strides = 1, padding = \"valid\", activation = None)(allm)\n",
    "        \n",
    "        print(\"Output\", allrc)\n",
    "        model = Model(inputs=[m10.input, m20.input, inpPS], outputs = allrc)\n",
    "#         print([n.input_tensors.name for n in model.get_layer('A_3').inbound_nodes])\n",
    "        adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=0, amsgrad=False)\n",
    "\n",
    "        model.compile(loss=shLoss, optimizer='adam' , metrics=['mae'])\n",
    "\n",
    "        if chk >=0 :\n",
    "            print(\"loading existing weights !!!\")\n",
    "            model.load_weights('final.h5')\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "    def fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, steps_per_epoch):   \n",
    "        hist = self.model.fit(x, y, batch_size, epochs, verbose, callbacks, validation_data=validation_data, steps_per_epoch=steps_per_epoch)\n",
    "        return hist.history\n",
    "\n",
    "\n",
    "chk = -1\n",
    "net = SRResnet(images_210, images_220, images_ps, lr = lr ,scale = scale , chk = chk)\n",
    "net.visualize()\n",
    "# net.get_model().summary()\n",
    "\n",
    "my_callbacks =[\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}',\n",
    "              monitor = \"loss\",\n",
    "              verbose = 1,\n",
    "              save_best_only = True,\n",
    "              save_freq = \"epoch\"\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "              monitor = \"loss\",\n",
    "              factor = 0.9,\n",
    "              patience = 20,\n",
    "              verbose = 1,\n",
    "              min_lr = 0.0001 / 10\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "              monitor = \"loss\",\n",
    "              min_delta = 2,\n",
    "              patience = 200,\n",
    "              verbose = 1,\n",
    "              baseline = None,\n",
    "              restore_best_weights = False\n",
    "            ),\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN MODEL ###\n",
    "model20 = net.get_model()\n",
    "model20.summary()\n",
    "%tensorboard --logdir logs/\n",
    "model20.fit(x=[images_210_train, images_220_train, images_ps_train], y=label_20_train, batch_size=batch_size1, epochs=epochs1, verbose=1, callbacks=my_callbacks, validation_data=([images_210_val, images_220_val, images_ps_val], label_20_val))#, validation_steps = 3) #steps_per_epoch=steps_per_epoch\n",
    "\n",
    "model20.save(output_folder + date + 'trained_20m_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old models and log files\n",
    "files_list = os.listdir()\n",
    "\n",
    "for file in files_list:\n",
    "    if 'model' in file:\n",
    "        shutil.rmtree(file)\n",
    "        \n",
    "for file in files_list:\n",
    "    if 'logs' in file:\n",
    "        shutil.rmtree(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SuperResTraining.ipynb",
   "provenance": [
    {
     "file_id": "1VukqUxz4-vHATexEbhopb93b-wDVwQ0l",
     "timestamp": 1635269540595
    },
    {
     "file_id": "1SLGUAH7f6cTH7WMEFnOSuL3LxtMlHVdJ",
     "timestamp": 1634931909576
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
