{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook is built to develop and train the RCCN model for the 20 m bands (NIR2, RE bands, and SWIR bands). Only blocks 2 and 3 will need to be edited by the user to provide the necessary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p7kNDltfZnld"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:46:37.449802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,MaxPool2D ,Convolution2D , Add, Dense , AveragePooling2D , UpSampling2D , Reshape , Flatten , Subtract , Concatenate, Cropping2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "os.chdir('...')\n",
    "\n",
    "# Provide a folder with which to place the final model. \n",
    "# IMPORTANT: DO NOT put the same folder as the imagery.Temporary models will be stored there,\n",
    "# but then deleted. If you do not give a separate location for the complete models, they will also be deleted.\n",
    "# Ensure there is a '/' at the end.\n",
    "output_folder = \".../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1635267928824,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "44EfYevlcbCM",
    "outputId": "679fc8e2-0f44-48c3-8a91-0ee8aea7efa7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of downsampled Sentinel-2 10m array:  (500, 500, 5)\n",
      "Shape of downsampled Sentinel-2 20m array:  (250, 250, 7)\n",
      "Shape of downsampled Dove array:  (2000, 2000, 5)\n",
      "Shape of downsampled Dove orbit array:  (2000, 2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# This date (or file identifier) should match what was used in BeautySchoolDropout\n",
    "date = '17Jun21_'\n",
    "\n",
    "# These two files correspond to the Pyrite output.  Choose the files with the EXACT SAME ratio (10to80, 20to160)\n",
    "s210m_80_fn = \"T16TCR_20210617T164839_10to80_stack_norm.tif\" \n",
    "s220m_160_fn = \"T16TCR_20210617T164839_20to160_stack_norm.tif\" \n",
    "\n",
    "# Ground truth. Choose the file that ends with \"20_stack_norm.tif\"\n",
    "s220m_20_fn = \"T16TCR_20210617T164839_20_stack_norm.tif\" \n",
    "\n",
    "# If you gave the same identifier above as used in BeautySchoolDropout, this should run without further change\n",
    "dove20_fn = \"%sDove_10m_mosaic.tif\" %date # 4 bands + mask\n",
    "dove20orb_fn = \"%sDove_Orbits_10m.tif\" %date # orbit(strip number)\n",
    "\n",
    "s210m_80 = rasterio.open(s210m_80_fn).read().T\n",
    "s220m_160 = rasterio.open(s220m_160_fn).read().T\n",
    "dove20 = rasterio.open(dove20_fn).read().T\n",
    "dove20_orbits = rasterio.open(dove20orb_fn).read().T\n",
    "\n",
    "print('Shape of downsampled Sentinel-2 10m array: ', s210m_80.shape)\n",
    "print('Shape of downsampled Sentinel-2 20m array: ', s220m_160.shape)\n",
    "print('Shape of downsampled Dove array: ', dove20.shape)\n",
    "print('Shape of downsampled Dove orbit array: ', dove20_orbits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 2001, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s220m_20 = rasterio.open(s220m_20_fn).read().T\n",
    "s220m_20 = s220m_20[:,:, :-1].copy()  # Remove mask for model validation \n",
    "\n",
    "s220m_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000, 4)\n",
      "(2000, 2000, 9)\n"
     ]
    }
   ],
   "source": [
    "encoded = ku.to_categorical(dove20_orbits, dtype='uint16')\n",
    "print(encoded.shape)\n",
    "\n",
    "dove20_with_orb = np.concatenate((dove20, encoded),axis=-1)\n",
    "print(dove20_with_orb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1237,
     "status": "ok",
     "timestamp": 1635267932338,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "-Po_bHlNdmNJ",
    "outputId": "d05d1744-59f7-4fd5-a498-1e21ce151d8d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking image  1\n",
      "Shape is good:  (500, 500, 5)\n",
      "Checking image  2\n",
      "Shape is good:  (250, 250, 7)\n",
      "Checking image  3\n",
      "Shape is good:  (2000, 2000, 9)\n",
      "Checking image  4\n",
      "Shape is good:  (2001, 2001, 6)\n"
     ]
    }
   ],
   "source": [
    "# Check for shape symetry and pad with zeros as needed\n",
    "model_images = [s210m_80, s220m_160, dove20_with_orb, s220m_20]\n",
    "\n",
    "for num, img in enumerate(model_images):   \n",
    "    print('Checking image ', num+1)    \n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        if img.shape[0] - img.shape[1] <= 3 and img.shape[0] - img.shape[1] > 0:\n",
    "            factor = img.shape[0] - img.shape[1]\n",
    "            print('%s more pixels in height' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, 0), (0, factor), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "        elif img.shape[1] - img.shape[0] <= 3 and img.shape[1] - img.shape[0] > 0:\n",
    "            factor = img.shape[1] - img.shape[0]        \n",
    "            print('%s more pixels in width' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, factor), (0, 0), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "    else:\n",
    "        print('Shape is good: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for compatibility among images\n",
    "mod_res_compare_size = model_images[0].shape[0]*4\n",
    "\n",
    "if model_images[2].shape[0] < mod_res_compare_size:\n",
    "    print('Fixing size compatibility. ')\n",
    "    diff = mod_res_compare_size - model_images[2].shape[0]\n",
    "    if diff < 5:\n",
    "        model_images[2] = np.pad(model_images[2], ((0, 0), (0, diff), (0, 0)))\n",
    "        model_images[2] = np.pad(model_images[2], ((0, diff), (0, 0), (0, 0)))\n",
    "        print('Padded with zeros. New shape: ', model_images[2].shape)\n",
    "    else:\n",
    "        print('Image size compatibility error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SiuRB6K6eI5R"
   },
   "outputs": [],
   "source": [
    "def get_test_patches(dset_10m, dset_20m, ps, dset_20gt, patchSize=24, border=4, ps_patch=96, ps_border=16):\n",
    "\n",
    "    PATCH_SIZE_HR = (patchSize, patchSize)\n",
    "    PATCH_SIZE_LR = [p//2 for p in PATCH_SIZE_HR]\n",
    "    BORDER_HR = border\n",
    "    BORDER_LR = BORDER_HR//2\n",
    "    PATCH_SIZE_PS = (ps_patch, ps_patch)\n",
    "    PATCH_SIZE_GT = (ps_patch-2*ps_border, ps_patch-2*ps_border)\n",
    "    \n",
    "    # Mirror the data at the borders to have the same dimensions as the input\n",
    "    dset_10 = np.pad(dset_10m, ((BORDER_HR, BORDER_HR), (BORDER_HR, BORDER_HR), (0, 0)))\n",
    "    dset_20 = np.pad(dset_20m, ((BORDER_LR, BORDER_LR), (BORDER_LR, BORDER_LR), (0, 0)))\n",
    "    dset_ps = np.pad(ps, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    dset_gt = np.pad(dset_20gt, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))  \n",
    "\n",
    "    BANDS10 = dset_10.shape[2]\n",
    "    BANDS20 = dset_20.shape[2]\n",
    "    BANDSps = dset_ps.shape[2]\n",
    "    BANDSgt = dset_gt.shape[2]\n",
    "    patchesAlongi = (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    patchesAlongj = (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    nr_patches = (patchesAlongi + 1) * (patchesAlongj + 1)\n",
    "\n",
    "    label_20 = np.zeros((nr_patches, BANDSgt) + PATCH_SIZE_GT).astype(np.float32)   #initialize with PATCH_SIZE_PS but crop to PATCH_SIZE_GT\n",
    "    image_20 = np.zeros((nr_patches, BANDS20) + tuple(PATCH_SIZE_LR)).astype(np.float32)\n",
    "    image_10 = np.zeros((nr_patches, BANDS10) + PATCH_SIZE_HR).astype(np.float32)\n",
    "    image_ps = np.zeros((nr_patches, BANDSps) + PATCH_SIZE_PS).astype(np.float32)\n",
    "\n",
    "    range_i = np.arange(0, (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    range_j = np.arange(0, (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    if not (np.mod(dset_20.shape[0] - 2 * BORDER_LR, PATCH_SIZE_LR[0] - 2 * BORDER_LR) == 0):\n",
    "        range_i = np.append(range_i, (dset_20.shape[0] - PATCH_SIZE_LR[0]))\n",
    "    if not (np.mod(dset_20.shape[1] - 2 * BORDER_LR, PATCH_SIZE_LR[1] - 2 * BORDER_LR) == 0):\n",
    "        range_j = np.append(range_j, (dset_20.shape[1] - PATCH_SIZE_LR[1]))\n",
    "\n",
    "    pCount = 0\n",
    "    for ii in range_i.astype(int):\n",
    "        for jj in range_j.astype(int):\n",
    "            upper_left_i = ii\n",
    "            upper_left_j = jj\n",
    "            crop_point_lr = [upper_left_i,\n",
    "                             upper_left_j,\n",
    "                             upper_left_i + PATCH_SIZE_LR[0],\n",
    "                             upper_left_j + PATCH_SIZE_LR[1]]\n",
    "            crop_point_hr = [p*2 for p in crop_point_lr]\n",
    "            crop_point_ps = [p*4 for p in crop_point_hr]\n",
    "            crop_point_gt = [p*4 for p in crop_point_hr]\n",
    "\n",
    "            \n",
    "            label_20[pCount] = np.rollaxis(dset_gt[crop_point_gt[0]+ps_border:crop_point_gt[2]-ps_border, \n",
    "                                                crop_point_gt[1]+ps_border:crop_point_gt[3]-ps_border], 2)\n",
    "            \n",
    "            image_20[pCount] = np.rollaxis(dset_20[crop_point_lr[0]:crop_point_lr[2],\n",
    "                             crop_point_lr[1]:crop_point_lr[3]], 2)\n",
    "            \n",
    "            image_10[pCount] = np.rollaxis(dset_10[crop_point_hr[0]:crop_point_hr[2],\n",
    "                             crop_point_hr[1]:crop_point_hr[3]], 2)\n",
    "            \n",
    "            image_ps[pCount] = np.rollaxis(dset_ps[crop_point_ps[0]:crop_point_ps[2],\n",
    "                             crop_point_ps[1]:crop_point_ps[3]], 2)\n",
    "            pCount += 1\n",
    "\n",
    "    return image_10, image_20, image_ps, label_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1635268003472,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "2DclF1KceMrS",
    "outputId": "a86369a8-9f16-48ea-a616-4909a330511e"
   },
   "outputs": [],
   "source": [
    "images_210, images_220, images_ps, label_20 = get_test_patches(model_images[0], model_images[1], model_images[2], model_images[3])\n",
    "#images_210, images_220, images_ps, label_20 = get_test_patches(s210m_40, s220m_80, dove10_with_orb, s220m_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1635268005432,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "s94kbHRwePXH",
    "outputId": "54691f7f-e3ec-4a1e-f1f9-5d4dd1babf7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 24, 24, 5)\n",
      "(1024, 12, 12, 7)\n",
      "(1024, 96, 96, 9)\n",
      "(1024, 64, 64, 6)\n"
     ]
    }
   ],
   "source": [
    "images_210 = np.moveaxis(images_210, 1, 3)\n",
    "images_220 = np.moveaxis(images_220, 1, 3)\n",
    "images_ps = np.moveaxis(images_ps, 1, 3)\n",
    "label_20 = np.moveaxis(label_20, 1, 3)\n",
    "\n",
    "print(images_210.shape)\n",
    "print(images_220.shape)\n",
    "print(images_ps.shape)\n",
    "print(label_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eokpDUcOeaQ6"
   },
   "outputs": [],
   "source": [
    "images_210_tr1, images_210_test, images_220_tr1, images_220_test, images_ps_tr1, images_ps_test, label_20_tr1, label_20_test = train_test_split(images_210, images_220, images_ps, label_20, test_size=0.1, random_state=1)\n",
    "images_210_train, images_210_val, images_220_train, images_220_val, images_ps_train, images_ps_val, label_20_train, label_20_val = train_test_split(images_210_tr1, images_220_tr1, images_ps_tr1, label_20_tr1, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7799,
     "status": "ok",
     "timestamp": 1635268025239,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "fzts5DOledmK",
    "outputId": "f4c0bdb9-659a-44c3-ab43-01772c536d1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:05.284847: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-14 12:47:05.288930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-14 12:47:05.383062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.384144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-12-14 12:47:05.384217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 12:47:05.430173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 12:47:05.430366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-14 12:47:05.455228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-14 12:47:05.461839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-14 12:47:05.515030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-14 12:47:05.522974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-14 12:47:05.617704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 12:47:05.618104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.619300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.620271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-14 12:47:05.621084: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-14 12:47:05.622533: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-14 12:47:05.622818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.623843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-12-14 12:47:05.623935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 12:47:05.624008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 12:47:05.624072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-14 12:47:05.624134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-14 12:47:05.624195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-14 12:47:05.624257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-14 12:47:05.624323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-14 12:47:05.624385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 12:47:05.624578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.625681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:05.626604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-14 12:47:05.627348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 12:47:06.383291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-14 12:47:06.383310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-14 12:47:06.383314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-14 12:47:06.383776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:06.384055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:06.384287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 12:47:06.384494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6916 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S220c shape is (None, 12, 12, 2240)\n",
      "S220s shape is (None, 96, 96, 35)\n",
      "S210c shape is (None, 24, 24, 400)\n",
      "S210s shape is (None, 96, 96, 25)\n",
      "all_inp shape is (None, 96, 96, 69)\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_2/add:0', description=\"created by layer 'add_2'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_3/add:0', description=\"created by layer 'add_3'\")\n",
      "BofRDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='rdb_out/BiasAdd:0', description=\"created by layer 'rdb_out'\")\n",
      "Cropping KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 128), dtype=tf.float32, name=None), name='cropping2d/strided_slice:0', description=\"created by layer 'cropping2d'\")\n",
      "Output KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 6), dtype=tf.float32, name=None), name='conv2d_5/BiasAdd:0', description=\"created by layer 'conv2d_5'\")\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:06.569173: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-14 12:47:06.569194: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-14 12:47:06.569894: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2021-12-14 12:47:06.575333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2021-12-14 12:47:06.654278: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-14 12:47:06.654372: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "batch_size1 = 32\n",
    "epochs1 = 100\n",
    "steps_per_epoch = 300\n",
    "tryout = 200\n",
    "gpu = 16 #check\n",
    "sample = 32\n",
    "mlt = 5\n",
    "scale = 8\n",
    "# patch_size = int(scale * 1024)\n",
    "patch_size = 96\n",
    "\n",
    "test_only = False\n",
    "\n",
    "chk = 1\n",
    "CHANNEL = 3\n",
    "\n",
    "def shLoss(y_true, y_pred, delta=2.0):\n",
    "    diff = y_true-y_pred\n",
    "    dsq = tf.keras.backend.square(delta)\n",
    "    return tf.keras.backend.mean( dsq * (tf.sqrt(1+ tf.square(diff)/dsq)-1), axis=-1)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "        return 10* k.log(255**2 /(k.mean(k.square(y_pred - y_true))))\n",
    "\n",
    "\n",
    "class SRResnet:\n",
    "    def L1_loss(self , y_true , y_pred):\n",
    "        return k.mean(k.abs(y_true - y_pred))\n",
    "    \n",
    "    def RDBlocks(self, x, name, count = 6, filter_count=32, RDB_feat=64):\n",
    "        ## 6 layers of RDB block\n",
    "        ## this thing need to be in a damn loop for more customisability\n",
    "        li = [x]\n",
    "        pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu' , name = name+'_conv1')(x)\n",
    "\n",
    "        for i in range(2 , count+1):\n",
    "            li.append(pas)\n",
    "            out =  Concatenate(axis = -1)(li) # conctenated output self.channel_axis\n",
    "            pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu', name = name+'_conv'+str(i))(out)\n",
    "\n",
    "        li.append(pas)\n",
    "        out1 = Concatenate(axis = -1)(li) #self.channel_axis\n",
    "        feat = Convolution2D(filters=RDB_feat, kernel_size=(1,1), strides=(1, 1), padding='same',activation='relu' , name = name+'_Local_Conv')(out1)\n",
    "\n",
    "        feat = Add()([feat , x])\n",
    "        print(\"RDBlocks\",feat)\n",
    "        return feat\n",
    "        \n",
    "    def visualize(self):\n",
    "        plot_model(self.model, to_file='model.png' , show_shapes = True)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def Block_Of_RDBBlocks(self, inp, RDB_count=20, count=6, filter_count=32, RDB_feat=64, end_feat=64):\n",
    "        \n",
    "        pass1 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(inp)\n",
    "\n",
    "        pass2 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pass1)\n",
    "\n",
    "\n",
    "        RDB = self.RDBlocks(pass2 , 'RDB1', count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "        RDBlocks_list = [RDB,]\n",
    "        for i in range(2,RDB_count+1):\n",
    "            RDB = self.RDBlocks(RDB ,'RDB'+str(i), count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "            RDBlocks_list.append(RDB)\n",
    "        out = Concatenate(axis = -1)(RDBlocks_list) #self.channel_axis\n",
    "        out = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(out)\n",
    "        output = Add()([out, pass1])\n",
    "        output = Convolution2D(filters=end_feat, kernel_size=(3,3), strides=(1,1), padding='same', name=\"rdb_out\")(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __init__(self, s10img, s20img, psimg, lr=0.00005, patch_size=32, RDB_count=4, count=2, filter_count=64, RDB_feat=128, end_feat=128, chk = -1, scale = 4):\n",
    "        self.channel_axis = 3\n",
    "        inp10 = Input(shape = (s10img.shape[1], s10img.shape[2], s10img.shape[3]))   # (24,24,4)\n",
    "        inp20 = Input(shape = (s20img.shape[1], s20img.shape[2], s20img.shape[3]))   # (12,12,6)\n",
    "        inpPS = Input(shape = (psimg.shape[1], psimg.shape[2], psimg.shape[3]))   # (96,96,9)\n",
    "\n",
    "        Subpixel_scale8 = Lambda(lambda x:tf.nn.depth_to_space(x,8))\n",
    "        Subpixel_scale4 = Lambda(lambda x:tf.nn.depth_to_space(x,4))\n",
    "        \n",
    "        s220c = Convolution2D(filters = (s20img.shape[3])*8*8*mlt, kernel_size=1, strides=1, padding='valid')(inp20)\n",
    "        print(\"S220c shape is\", s220c.shape)\n",
    "        s220s = Subpixel_scale8(inputs=s220c)\n",
    "        print(\"S220s shape is\", s220s.shape)\n",
    "        m20 = Model(inputs=inp20, outputs=s220s)\n",
    "        s210c = Convolution2D(filters = (s10img.shape[3])*4*4*mlt, kernel_size=1, strides=1, padding='valid')(inp10)\n",
    "        print(\"S210c shape is\", s210c.shape)\n",
    "        s210s = Subpixel_scale4(inputs=s210c)\n",
    "        print(\"S210s shape is\", s210s.shape)\n",
    "        m10 = Model(inputs=inp10, outputs=s210s)\n",
    "        \n",
    "        all_inp = Concatenate(axis=-1)([m10.output, m20.output, inpPS])\n",
    "        print(\"all_inp shape is\", all_inp.shape)\n",
    "        allb = self.Block_Of_RDBBlocks(all_inp, RDB_count, count, filter_count, RDB_feat, end_feat)\n",
    "        print(\"BofRDBlocks\",allb)\n",
    "        allm = Cropping2D(cropping=16)(allb)\n",
    "        print(\"Cropping\",allm)\n",
    "        allrc = Convolution2D(filters = 6, kernel_size = 1, strides = 1, padding = \"valid\", activation = None)(allm)\n",
    "        \n",
    "        print(\"Output\", allrc)\n",
    "        model = Model(inputs=[m10.input, m20.input, inpPS], outputs = allrc)\n",
    "#         print([n.input_tensors.name for n in model.get_layer('A_3').inbound_nodes])\n",
    "        adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=0, amsgrad=False)\n",
    "\n",
    "        model.compile(loss=shLoss, optimizer='adam' , metrics=['mae'])\n",
    "\n",
    "        if chk >=0 :\n",
    "            print(\"loading existing weights !!!\")\n",
    "            model.load_weights('final.h5')\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "    def fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, steps_per_epoch):   \n",
    "        hist = self.model.fit(x, y, batch_size, epochs, verbose, callbacks, validation_data=validation_data, steps_per_epoch=steps_per_epoch)\n",
    "        return hist.history\n",
    "\n",
    "\n",
    "chk = -1\n",
    "net = SRResnet(images_210, images_220, images_ps, lr = lr ,scale = scale , chk = chk)\n",
    "net.visualize()\n",
    "# net.get_model().summary()\n",
    "\n",
    "my_callbacks =[\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}',\n",
    "              monitor = \"loss\",\n",
    "              verbose = 1,\n",
    "              save_best_only = True,\n",
    "              save_freq = \"epoch\"\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "              monitor = \"loss\",\n",
    "              factor = 0.9,\n",
    "              patience = 20,\n",
    "              verbose = 1,\n",
    "              min_lr = 0.0001 / 10\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "              monitor = \"loss\",\n",
    "              min_delta = 2,\n",
    "              patience = 200,\n",
    "              verbose = 1,\n",
    "              baseline = None,\n",
    "              restore_best_weights = False\n",
    "            ),\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 24, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12, 12, 7)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 400)  2400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 12, 12, 2240) 17920       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 96, 96, 25)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 96, 96, 35)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 96, 96, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96, 96, 69)   0           lambda_1[0][0]                   \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 128)  79616       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_conv1 (Conv2D)             (None, 96, 96, 64)   73792       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 192)  0           conv2d_3[0][0]                   \n",
      "                                                                 RDB1_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 RDB1_conv1[0][0]                 \n",
      "                                                                 RDB1_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 96, 96, 128)  0           RDB1_Local_Conv[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 96, 96, 192)  0           add[0][0]                        \n",
      "                                                                 RDB2_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 256)  0           add[0][0]                        \n",
      "                                                                 RDB2_conv1[0][0]                 \n",
      "                                                                 RDB2_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 96, 96, 128)  0           RDB2_Local_Conv[0][0]            \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 96, 96, 192)  0           add_1[0][0]                      \n",
      "                                                                 RDB3_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 96, 256)  0           add_1[0][0]                      \n",
      "                                                                 RDB3_conv1[0][0]                 \n",
      "                                                                 RDB3_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 96, 96, 128)  0           RDB3_Local_Conv[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96, 96, 192)  0           add_2[0][0]                      \n",
      "                                                                 RDB4_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96, 96, 256)  0           add_2[0][0]                      \n",
      "                                                                 RDB4_conv1[0][0]                 \n",
      "                                                                 RDB4_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 96, 96, 128)  0           RDB4_Local_Conv[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 96, 96, 512)  0           add[0][0]                        \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 96, 128)  589952      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 96, 96, 128)  0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rdb_out (Conv2D)                (None, 96, 96, 128)  147584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 64, 64, 128)  0           rdb_out[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 6)    774         cropping2d[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,855,206\n",
      "Trainable params: 1,855,206\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7e709a3b6315ad8f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7e709a3b6315ad8f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:08.967714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-14 12:47:08.987841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:09.787240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 12:47:10.868696: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-14 12:47:10.908690: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-12-14 12:47:11.286059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 12:47:16.379627: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:17.964789: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:18.371893: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:19.721754: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:21.097961: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.79GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 6:30 - loss: 39933.9727 - mae: 19968.9863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:24.649355: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-14 12:47:24.649375: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/26 [=>............................] - ETA: 10s - loss: 135058.4395 - mae: 67531.2197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:25.084671: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-14 12:47:25.092062: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2021-12-14 12:47:25.095552: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 497 callback api events and 485 activity events. \n",
      "2021-12-14 12:47:25.103217: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-14 12:47:25.111534: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_14_12_47_25\n",
      "2021-12-14 12:47:25.116824: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.trace.json.gz\n",
      "2021-12-14 12:47:25.136323: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_14_12_47_25\n",
      "2021-12-14 12:47:25.139209: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.memory_profile.json.gz\n",
      "2021-12-14 12:47:25.139889: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_14_12_47_25Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_14_12_47_25/pop-os.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 68523.2430 - mae: 34263.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:39.788277: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:41.979840: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 12:47:43.371566: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 47s 1s/step - loss: 65655.1110 - mae: 32829.5539 - val_loss: 4212.0898 - val_mae: 2108.0386\n",
      "\n",
      "Epoch 00001: loss improved from inf to 29803.46094, saving model to model.01-4212.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 12:47:56.147095: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.01-4212.09/assets\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 11s 423ms/step - loss: 3873.5924 - mae: 1938.7894 - val_loss: 2866.4133 - val_mae: 1435.1992\n",
      "\n",
      "Epoch 00002: loss improved from 29803.46094 to 3486.73096, saving model to model.02-2866.41\n",
      "INFO:tensorflow:Assets written to: model.02-2866.41/assets\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 11s 414ms/step - loss: 2668.4204 - mae: 1336.2005 - val_loss: 1917.1438 - val_mae: 960.5587\n",
      "\n",
      "Epoch 00003: loss improved from 3486.73096 to 2357.76440, saving model to model.03-1917.14\n",
      "INFO:tensorflow:Assets written to: model.03-1917.14/assets\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 11s 441ms/step - loss: 1952.9232 - mae: 978.4485 - val_loss: 2577.5681 - val_mae: 1290.7738\n",
      "\n",
      "Epoch 00004: loss improved from 2357.76440 to 1996.77893, saving model to model.04-2577.57\n",
      "INFO:tensorflow:Assets written to: model.04-2577.57/assets\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 12s 454ms/step - loss: 2313.1946 - mae: 1158.5875 - val_loss: 2180.4119 - val_mae: 1092.1979\n",
      "\n",
      "Epoch 00005: loss did not improve from 1996.77893\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 12s 448ms/step - loss: 1868.9521 - mae: 936.4637 - val_loss: 1762.3088 - val_mae: 883.1422\n",
      "\n",
      "Epoch 00006: loss improved from 1996.77893 to 1754.52551, saving model to model.06-1762.31\n",
      "INFO:tensorflow:Assets written to: model.06-1762.31/assets\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 11s 428ms/step - loss: 1843.3957 - mae: 923.6859 - val_loss: 1742.9845 - val_mae: 873.4799\n",
      "\n",
      "Epoch 00007: loss did not improve from 1754.52551\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 11s 431ms/step - loss: 1726.7249 - mae: 865.3494 - val_loss: 1451.0780 - val_mae: 727.5219\n",
      "\n",
      "Epoch 00008: loss improved from 1754.52551 to 1724.18188, saving model to model.08-1451.08\n",
      "INFO:tensorflow:Assets written to: model.08-1451.08/assets\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 1556.2371 - mae: 780.1032 - val_loss: 1421.1570 - val_mae: 712.5616\n",
      "\n",
      "Epoch 00009: loss improved from 1724.18188 to 1594.18311, saving model to model.09-1421.16\n",
      "INFO:tensorflow:Assets written to: model.09-1421.16/assets\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 11s 437ms/step - loss: 1548.0542 - mae: 776.0115 - val_loss: 1449.1764 - val_mae: 726.5712\n",
      "\n",
      "Epoch 00010: loss improved from 1594.18311 to 1505.21899, saving model to model.10-1449.18\n",
      "INFO:tensorflow:Assets written to: model.10-1449.18/assets\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 11s 437ms/step - loss: 1485.8522 - mae: 744.9102 - val_loss: 1822.0862 - val_mae: 913.0339\n",
      "\n",
      "Epoch 00011: loss improved from 1505.21899 to 1477.68628, saving model to model.11-1822.09\n",
      "INFO:tensorflow:Assets written to: model.11-1822.09/assets\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1560.2888 - mae: 782.1298 - val_loss: 1409.6022 - val_mae: 706.7843\n",
      "\n",
      "Epoch 00012: loss did not improve from 1477.68628\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 1538.3842 - mae: 771.1776 - val_loss: 1511.8309 - val_mae: 757.9012\n",
      "\n",
      "Epoch 00013: loss did not improve from 1477.68628\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1606.5336 - mae: 805.2531 - val_loss: 1853.6541 - val_mae: 928.8156\n",
      "\n",
      "Epoch 00014: loss did not improve from 1477.68628\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 11s 436ms/step - loss: 1759.4558 - mae: 881.7160 - val_loss: 3095.9009 - val_mae: 1549.9474\n",
      "\n",
      "Epoch 00015: loss did not improve from 1477.68628\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 11s 436ms/step - loss: 2370.2574 - mae: 1187.1213 - val_loss: 2165.3181 - val_mae: 1084.6511\n",
      "\n",
      "Epoch 00016: loss did not improve from 1477.68628\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 11s 437ms/step - loss: 1931.3911 - mae: 967.6864 - val_loss: 1912.1515 - val_mae: 958.0676\n",
      "\n",
      "Epoch 00017: loss did not improve from 1477.68628\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 11s 437ms/step - loss: 1731.8676 - mae: 867.9221 - val_loss: 1322.1915 - val_mae: 663.0787\n",
      "\n",
      "Epoch 00018: loss did not improve from 1477.68628\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 11s 437ms/step - loss: 1403.3075 - mae: 703.6376 - val_loss: 1329.8319 - val_mae: 666.8989\n",
      "\n",
      "Epoch 00019: loss improved from 1477.68628 to 1394.97766, saving model to model.19-1329.83\n",
      "INFO:tensorflow:Assets written to: model.19-1329.83/assets\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 11s 441ms/step - loss: 1360.8907 - mae: 682.4280 - val_loss: 1250.5098 - val_mae: 627.2352\n",
      "\n",
      "Epoch 00020: loss improved from 1394.97766 to 1336.86047, saving model to model.20-1250.51\n",
      "INFO:tensorflow:Assets written to: model.20-1250.51/assets\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 11s 441ms/step - loss: 1260.7416 - mae: 632.3515 - val_loss: 1212.3743 - val_mae: 608.1667\n",
      "\n",
      "Epoch 00021: loss improved from 1336.86047 to 1289.52527, saving model to model.21-1212.37\n",
      "INFO:tensorflow:Assets written to: model.21-1212.37/assets\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1284.4919 - mae: 644.2276 - val_loss: 1173.8409 - val_mae: 588.8990\n",
      "\n",
      "Epoch 00022: loss did not improve from 1289.52527\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1253.4945 - mae: 628.7280 - val_loss: 1193.3524 - val_mae: 598.6558\n",
      "\n",
      "Epoch 00023: loss improved from 1289.52527 to 1278.57800, saving model to model.23-1193.35\n",
      "INFO:tensorflow:Assets written to: model.23-1193.35/assets\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 11s 443ms/step - loss: 1287.5616 - mae: 645.7623 - val_loss: 1393.4813 - val_mae: 698.7265\n",
      "\n",
      "Epoch 00024: loss improved from 1278.57800 to 1275.74365, saving model to model.24-1393.48\n",
      "INFO:tensorflow:Assets written to: model.24-1393.48/assets\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 11s 440ms/step - loss: 1417.2697 - mae: 710.6198 - val_loss: 1344.8337 - val_mae: 674.4023\n",
      "\n",
      "Epoch 00025: loss did not improve from 1275.74365\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1386.5451 - mae: 695.2566 - val_loss: 1250.7509 - val_mae: 627.3571\n",
      "\n",
      "Epoch 00026: loss did not improve from 1275.74365\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1265.9719 - mae: 634.9685 - val_loss: 1294.0714 - val_mae: 649.0167\n",
      "\n",
      "Epoch 00027: loss did not improve from 1275.74365\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1241.4446 - mae: 622.7034 - val_loss: 1289.6682 - val_mae: 646.8181\n",
      "\n",
      "Epoch 00028: loss improved from 1275.74365 to 1255.17139, saving model to model.28-1289.67\n",
      "INFO:tensorflow:Assets written to: model.28-1289.67/assets\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1305.8959 - mae: 654.9311 - val_loss: 1313.5325 - val_mae: 658.7487\n",
      "\n",
      "Epoch 00029: loss did not improve from 1255.17139\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1350.0387 - mae: 677.0033 - val_loss: 1122.7013 - val_mae: 563.3295\n",
      "\n",
      "Epoch 00030: loss did not improve from 1255.17139\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1230.6131 - mae: 617.2880 - val_loss: 1088.6771 - val_mae: 546.3163\n",
      "\n",
      "Epoch 00031: loss improved from 1255.17139 to 1249.08789, saving model to model.31-1088.68\n",
      "INFO:tensorflow:Assets written to: model.31-1088.68/assets\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 12s 444ms/step - loss: 1208.2481 - mae: 606.1051 - val_loss: 1157.4611 - val_mae: 580.7118\n",
      "\n",
      "Epoch 00032: loss improved from 1249.08789 to 1229.98547, saving model to model.32-1157.46\n",
      "INFO:tensorflow:Assets written to: model.32-1157.46/assets\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 12s 442ms/step - loss: 1233.4586 - mae: 618.7108 - val_loss: 1163.8844 - val_mae: 583.9244\n",
      "\n",
      "Epoch 00033: loss improved from 1229.98547 to 1217.33569, saving model to model.33-1163.88\n",
      "INFO:tensorflow:Assets written to: model.33-1163.88/assets\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 11s 443ms/step - loss: 1201.7863 - mae: 602.8738 - val_loss: 1085.4611 - val_mae: 544.7099\n",
      "\n",
      "Epoch 00034: loss improved from 1217.33569 to 1198.85315, saving model to model.34-1085.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.34-1085.46/assets\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 12s 443ms/step - loss: 1220.6701 - mae: 612.3168 - val_loss: 1195.8362 - val_mae: 599.9020\n",
      "\n",
      "Epoch 00035: loss did not improve from 1198.85315\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1204.3485 - mae: 604.1563 - val_loss: 1430.6982 - val_mae: 717.3375\n",
      "\n",
      "Epoch 00036: loss did not improve from 1198.85315\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1289.2318 - mae: 646.5993 - val_loss: 1388.5420 - val_mae: 696.2578\n",
      "\n",
      "Epoch 00037: loss did not improve from 1198.85315\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1245.4385 - mae: 624.7016 - val_loss: 1223.3555 - val_mae: 613.6601\n",
      "\n",
      "Epoch 00038: loss improved from 1198.85315 to 1176.28198, saving model to model.38-1223.36\n",
      "INFO:tensorflow:Assets written to: model.38-1223.36/assets\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 12s 442ms/step - loss: 1180.6104 - mae: 592.2863 - val_loss: 1256.9269 - val_mae: 630.4490\n",
      "\n",
      "Epoch 00039: loss improved from 1176.28198 to 1170.71643, saving model to model.39-1256.93\n",
      "INFO:tensorflow:Assets written to: model.39-1256.93/assets\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1174.2798 - mae: 589.1212 - val_loss: 1049.4261 - val_mae: 526.6918\n",
      "\n",
      "Epoch 00040: loss did not improve from 1170.71643\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1141.0562 - mae: 572.5087 - val_loss: 1076.5551 - val_mae: 540.2570\n",
      "\n",
      "Epoch 00041: loss improved from 1170.71643 to 1145.19788, saving model to model.41-1076.56\n",
      "INFO:tensorflow:Assets written to: model.41-1076.56/assets\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1115.2552 - mae: 559.6076 - val_loss: 1216.3629 - val_mae: 610.1661\n",
      "\n",
      "Epoch 00042: loss did not improve from 1145.19788\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1190.8837 - mae: 597.4243 - val_loss: 1509.1084 - val_mae: 756.5433\n",
      "\n",
      "Epoch 00043: loss did not improve from 1145.19788\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 11s 440ms/step - loss: 1226.3208 - mae: 615.1429 - val_loss: 1122.1572 - val_mae: 563.0612\n",
      "\n",
      "Epoch 00044: loss did not improve from 1145.19788\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1104.8733 - mae: 554.4173 - val_loss: 1074.7046 - val_mae: 539.3337\n",
      "\n",
      "Epoch 00045: loss improved from 1145.19788 to 1130.93152, saving model to model.45-1074.70\n",
      "INFO:tensorflow:Assets written to: model.45-1074.70/assets\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1128.5007 - mae: 566.2317 - val_loss: 1012.8608 - val_mae: 508.4087\n",
      "\n",
      "Epoch 00046: loss improved from 1130.93152 to 1122.41406, saving model to model.46-1012.86\n",
      "INFO:tensorflow:Assets written to: model.46-1012.86/assets\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 11s 441ms/step - loss: 1080.2744 - mae: 542.1172 - val_loss: 1341.7063 - val_mae: 672.8414\n",
      "\n",
      "Epoch 00047: loss did not improve from 1122.41406\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1166.4455 - mae: 585.2046 - val_loss: 1045.7305 - val_mae: 524.8456\n",
      "\n",
      "Epoch 00048: loss improved from 1122.41406 to 1110.53101, saving model to model.48-1045.73\n",
      "INFO:tensorflow:Assets written to: model.48-1045.73/assets\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1103.9038 - mae: 553.9327 - val_loss: 1097.9720 - val_mae: 550.9675\n",
      "\n",
      "Epoch 00049: loss did not improve from 1110.53101\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1086.1362 - mae: 545.0486 - val_loss: 990.5356 - val_mae: 497.2455\n",
      "\n",
      "Epoch 00050: loss improved from 1110.53101 to 1086.05933, saving model to model.50-990.54\n",
      "INFO:tensorflow:Assets written to: model.50-990.54/assets\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 11s 442ms/step - loss: 1078.2234 - mae: 541.0918 - val_loss: 1255.1771 - val_mae: 629.5739\n",
      "\n",
      "Epoch 00051: loss did not improve from 1086.05933\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1112.5271 - mae: 558.2444 - val_loss: 948.4484 - val_mae: 476.2013\n",
      "\n",
      "Epoch 00052: loss improved from 1086.05933 to 1078.26746, saving model to model.52-948.45\n",
      "INFO:tensorflow:Assets written to: model.52-948.45/assets\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1017.0129 - mae: 510.4851 - val_loss: 1309.0325 - val_mae: 656.5033\n",
      "\n",
      "Epoch 00053: loss improved from 1078.26746 to 1068.78479, saving model to model.53-1309.03\n",
      "INFO:tensorflow:Assets written to: model.53-1309.03/assets\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 12s 443ms/step - loss: 1117.1531 - mae: 560.5581 - val_loss: 914.1594 - val_mae: 459.0549\n",
      "\n",
      "Epoch 00054: loss did not improve from 1068.78479\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 1080.6252 - mae: 542.2929 - val_loss: 942.5285 - val_mae: 473.2404\n",
      "\n",
      "Epoch 00055: loss did not improve from 1068.78479\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 11s 439ms/step - loss: 1025.3788 - mae: 514.6687 - val_loss: 1047.0151 - val_mae: 525.4894\n",
      "\n",
      "Epoch 00056: loss improved from 1068.78479 to 1066.08142, saving model to model.56-1047.02\n",
      "INFO:tensorflow:Assets written to: model.56-1047.02/assets\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 12s 449ms/step - loss: 1058.6529 - mae: 531.3075 - val_loss: 950.4703 - val_mae: 477.2121\n",
      "\n",
      "Epoch 00057: loss improved from 1066.08142 to 1033.08411, saving model to model.57-950.47\n",
      "INFO:tensorflow:Assets written to: model.57-950.47/assets\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 11s 441ms/step - loss: 1086.3110 - mae: 545.1365 - val_loss: 924.5629 - val_mae: 464.2579\n",
      "\n",
      "Epoch 00058: loss did not improve from 1033.08411\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1068.4217 - mae: 536.1910 - val_loss: 909.9995 - val_mae: 456.9756\n",
      "\n",
      "Epoch 00059: loss did not improve from 1033.08411\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 988.7304 - mae: 496.3435 - val_loss: 1053.7499 - val_mae: 528.8567\n",
      "\n",
      "Epoch 00060: loss improved from 1033.08411 to 998.52673, saving model to model.60-1053.75\n",
      "INFO:tensorflow:Assets written to: model.60-1053.75/assets\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 1021.0160 - mae: 512.4874 - val_loss: 1156.1700 - val_mae: 580.0700\n",
      "\n",
      "Epoch 00061: loss did not improve from 998.52673\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 1097.4350 - mae: 550.6992 - val_loss: 1117.8383 - val_mae: 560.9016\n",
      "\n",
      "Epoch 00062: loss did not improve from 998.52673\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1146.4637 - mae: 575.2139 - val_loss: 974.5348 - val_mae: 489.2466\n",
      "\n",
      "Epoch 00063: loss did not improve from 998.52673\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1075.8092 - mae: 539.8856 - val_loss: 906.5851 - val_mae: 455.2692\n",
      "\n",
      "Epoch 00064: loss did not improve from 998.52673\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1029.3923 - mae: 516.6758 - val_loss: 973.3560 - val_mae: 488.6567\n",
      "\n",
      "Epoch 00065: loss did not improve from 998.52673\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 1093.5187 - mae: 548.7407 - val_loss: 1126.8099 - val_mae: 565.3849\n",
      "\n",
      "Epoch 00066: loss did not improve from 998.52673\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1083.6400 - mae: 543.8004 - val_loss: 1027.4244 - val_mae: 515.6932\n",
      "\n",
      "Epoch 00067: loss did not improve from 998.52673\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1254.3145 - mae: 629.1413 - val_loss: 1308.7184 - val_mae: 656.3456\n",
      "\n",
      "Epoch 00068: loss did not improve from 998.52673\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 11s 430ms/step - loss: 1115.8979 - mae: 559.9303 - val_loss: 1080.3733 - val_mae: 542.1686\n",
      "\n",
      "Epoch 00069: loss did not improve from 998.52673\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1044.1318 - mae: 524.0458 - val_loss: 897.4879 - val_mae: 450.7209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: loss did not improve from 998.52673\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 931.6142 - mae: 467.7844 - val_loss: 1001.1781 - val_mae: 502.5676\n",
      "\n",
      "Epoch 00071: loss improved from 998.52673 to 972.82727, saving model to model.71-1001.18\n",
      "INFO:tensorflow:Assets written to: model.71-1001.18/assets\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 1017.3317 - mae: 510.6454 - val_loss: 1100.4969 - val_mae: 552.2317\n",
      "\n",
      "Epoch 00072: loss did not improve from 972.82727\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1019.5060 - mae: 511.7329 - val_loss: 863.1478 - val_mae: 433.5490\n",
      "\n",
      "Epoch 00073: loss did not improve from 972.82727\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 992.0514 - mae: 498.0049 - val_loss: 843.6072 - val_mae: 423.7777\n",
      "\n",
      "Epoch 00074: loss did not improve from 972.82727\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 975.6483 - mae: 489.8026 - val_loss: 853.4600 - val_mae: 428.7054\n",
      "\n",
      "Epoch 00075: loss improved from 972.82727 to 966.04144, saving model to model.75-853.46\n",
      "INFO:tensorflow:Assets written to: model.75-853.46/assets\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 949.1843 - mae: 476.5700 - val_loss: 838.2286 - val_mae: 421.0880\n",
      "\n",
      "Epoch 00076: loss improved from 966.04144 to 945.74573, saving model to model.76-838.23\n",
      "INFO:tensorflow:Assets written to: model.76-838.23/assets\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 928.7550 - mae: 466.3550 - val_loss: 868.7759 - val_mae: 436.3630\n",
      "\n",
      "Epoch 00077: loss did not improve from 945.74573\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 947.2889 - mae: 475.6219 - val_loss: 938.8553 - val_mae: 471.4051\n",
      "\n",
      "Epoch 00078: loss did not improve from 945.74573\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 996.2498 - mae: 500.1040 - val_loss: 864.4824 - val_mae: 434.2160\n",
      "\n",
      "Epoch 00079: loss did not improve from 945.74573\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 920.7872 - mae: 462.3707 - val_loss: 837.2975 - val_mae: 420.6229\n",
      "\n",
      "Epoch 00080: loss did not improve from 945.74573\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 951.1853 - mae: 477.5705 - val_loss: 951.7144 - val_mae: 477.8371\n",
      "\n",
      "Epoch 00081: loss did not improve from 945.74573\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 11s 428ms/step - loss: 982.8613 - mae: 493.4101 - val_loss: 838.4986 - val_mae: 421.2239\n",
      "\n",
      "Epoch 00082: loss did not improve from 945.74573\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 1002.8245 - mae: 503.3913 - val_loss: 1213.6646 - val_mae: 608.8188\n",
      "\n",
      "Epoch 00083: loss did not improve from 945.74573\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 1006.2314 - mae: 505.0954 - val_loss: 1023.4654 - val_mae: 513.7139\n",
      "\n",
      "Epoch 00084: loss did not improve from 945.74573\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 895.8440 - mae: 449.8986 - val_loss: 815.9406 - val_mae: 409.9440\n",
      "\n",
      "Epoch 00085: loss improved from 945.74573 to 909.34058, saving model to model.85-815.94\n",
      "INFO:tensorflow:Assets written to: model.85-815.94/assets\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 901.4028 - mae: 452.6777 - val_loss: 1051.1750 - val_mae: 527.5718\n",
      "\n",
      "Epoch 00086: loss did not improve from 909.34058\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 931.2015 - mae: 467.5778 - val_loss: 823.7418 - val_mae: 413.8459\n",
      "\n",
      "Epoch 00087: loss improved from 909.34058 to 904.27521, saving model to model.87-823.74\n",
      "INFO:tensorflow:Assets written to: model.87-823.74/assets\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 881.5551 - mae: 442.7538 - val_loss: 841.5304 - val_mae: 422.7400\n",
      "\n",
      "Epoch 00088: loss did not improve from 904.27521\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 943.2897 - mae: 473.6235 - val_loss: 1047.8883 - val_mae: 525.9265\n",
      "\n",
      "Epoch 00089: loss did not improve from 904.27521\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 11s 434ms/step - loss: 924.3784 - mae: 464.1670 - val_loss: 976.8875 - val_mae: 490.4242\n",
      "\n",
      "Epoch 00090: loss did not improve from 904.27521\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 988.8767 - mae: 496.4181 - val_loss: 916.1161 - val_mae: 460.0358\n",
      "\n",
      "Epoch 00091: loss did not improve from 904.27521\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 955.9941 - mae: 479.9752 - val_loss: 831.6620 - val_mae: 417.8057\n",
      "\n",
      "Epoch 00092: loss did not improve from 904.27521\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 909.4685 - mae: 456.7106 - val_loss: 813.8835 - val_mae: 408.9150\n",
      "\n",
      "Epoch 00093: loss did not improve from 904.27521\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 897.5841 - mae: 450.7683 - val_loss: 877.8765 - val_mae: 440.9160\n",
      "\n",
      "Epoch 00094: loss improved from 904.27521 to 900.32678, saving model to model.94-877.88\n",
      "INFO:tensorflow:Assets written to: model.94-877.88/assets\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 903.4021 - mae: 453.6777 - val_loss: 790.6457 - val_mae: 397.2960\n",
      "\n",
      "Epoch 00095: loss improved from 900.32678 to 881.49866, saving model to model.95-790.65\n",
      "INFO:tensorflow:Assets written to: model.95-790.65/assets\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 925.1835 - mae: 464.5701 - val_loss: 811.5678 - val_mae: 407.7571\n",
      "\n",
      "Epoch 00096: loss did not improve from 881.49866\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 925.8253 - mae: 464.8899 - val_loss: 814.6772 - val_mae: 409.3130\n",
      "\n",
      "Epoch 00097: loss did not improve from 881.49866\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 846.8175 - mae: 425.3837 - val_loss: 823.8790 - val_mae: 413.9139\n",
      "\n",
      "Epoch 00098: loss did not improve from 881.49866\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 878.2936 - mae: 441.1227 - val_loss: 780.5627 - val_mae: 392.2529\n",
      "\n",
      "Epoch 00099: loss did not improve from 881.49866\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 11s 432ms/step - loss: 924.2845 - mae: 464.1201 - val_loss: 808.8841 - val_mae: 406.4170\n",
      "\n",
      "Epoch 00100: loss did not improve from 881.49866\n",
      "INFO:tensorflow:Assets written to: /home/sarahwegmueller/Documents/Casden_dev/Lakewood_OW/TimeSeries/finals/17Jun21_trained_8x_model/assets\n"
     ]
    }
   ],
   "source": [
    "### TRAIN MODEL ###\n",
    "model20 = net.get_model()\n",
    "model20.summary()\n",
    "%tensorboard --logdir logs/\n",
    "model20.fit(x=[images_210_train, images_220_train, images_ps_train], y=label_20_train, batch_size=batch_size1, epochs=epochs1, verbose=1, callbacks=my_callbacks, validation_data=([images_210_val, images_220_val, images_ps_val], label_20_val))#, validation_steps = 3) #steps_per_epoch=steps_per_epoch\n",
    "\n",
    "model20.save(output_folder + date + 'trained_8x_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old models and log files\n",
    "files_list = os.listdir()\n",
    "\n",
    "for file in files_list:\n",
    "    if 'model' in file:\n",
    "        shutil.rmtree(file)\n",
    "        \n",
    "for file in files_list:\n",
    "    if 'logs' in file:\n",
    "        shutil.rmtree(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SuperResTraining.ipynb",
   "provenance": [
    {
     "file_id": "1VukqUxz4-vHATexEbhopb93b-wDVwQ0l",
     "timestamp": 1635269540595
    },
    {
     "file_id": "1SLGUAH7f6cTH7WMEFnOSuL3LxtMlHVdJ",
     "timestamp": 1634931909576
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
