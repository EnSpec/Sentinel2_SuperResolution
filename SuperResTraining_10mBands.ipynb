{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is built to develop and train the RCCN model for the 10 m bands (RGB and NIR).  Only blocks 2 and 3 will need to be edited by the user to provide the necessary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3819,
     "status": "ok",
     "timestamp": 1635428061968,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "p7kNDltfZnld"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:14.392756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,MaxPool2D ,Convolution2D , Add, Dense , AveragePooling2D , UpSampling2D , Reshape , Flatten , Subtract , Concatenate, Cropping2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "os.chdir('...')\n",
    "\n",
    "# Provide a folder with which to place the final model. \n",
    "# IMPORTANT: DO NOT put the same folder as the imagery.Temporary models will be stored there,\n",
    "# but then deleted. If you do not give a separate location for the complete models, they will also be deleted.\n",
    "# Ensure there is a '/' at the end.\n",
    "output_folder = \".../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11593,
     "status": "ok",
     "timestamp": 1635428106011,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "44EfYevlcbCM",
    "outputId": "8712900f-2745-40a6-e984-f31b3e3dca95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of downsampled Sentinel-2 10m array:  (1000, 1000, 5)\n",
      "Shape of downsampled Sentinel-2 20m array:  (500, 500, 7)\n",
      "Shape of downsampled Dove array:  (4000, 4000, 5)\n",
      "Shape of downsampled Dove orbit array:  (4000, 4000, 1)\n"
     ]
    }
   ],
   "source": [
    "# This date (or file identifier) should match what was used in BeautySchoolDropout\n",
    "date = '17Jun21_'\n",
    "\n",
    "# These two files correspond to the Pyrite output.  Choose the files with the EXACT SAME ratio (10to40, 20to80)\n",
    "s210m_40_fn = \"T16TCR_20210617T164839_10to40_stack_norm.tif\" \n",
    "s220m_80_fn = \"T16TCR_20210617T164839_20to80_stack_norm.tif\" \n",
    "\n",
    "# Ground truth. Choose the file that ends with \"10_stack_norm.tif\"\n",
    "s220m_20_fn = \"T16TCR_20210617T164839_10_stack_norm.tif\" \n",
    "\n",
    "# If you gave the same identifier above as used in BeautySchoolDropout, this should run without further change\n",
    "dove10_fn = \"%sDove_10m_mosaic.tif\" %date # 4 bands + mask\n",
    "dove10orb_fn = \"%sDove_Orbits_10m.tif\" %date # orbit(strip number)\n",
    "\n",
    "s210m_40 = rasterio.open(s210m_40_fn).read().T\n",
    "s220m_80 = rasterio.open(s220m_80_fn).read().T\n",
    "dove10 = rasterio.open(dove10_fn).read().T\n",
    "dove10_orbits = rasterio.open(dove10orb_fn).read().T\n",
    "\n",
    "print('Shape of downsampled Sentinel-2 10m array: ', s210m_40.shape)\n",
    "print('Shape of downsampled Sentinel-2 20m array: ', s220m_80.shape)\n",
    "print('Shape of downsampled Dove array: ', dove10.shape)\n",
    "print('Shape of downsampled Dove orbit array: ', dove10_orbits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4180,
     "status": "ok",
     "timestamp": 1635428110187,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "-Po_bHlNdmNJ",
    "outputId": "b5781ad2-847a-4b67-a3c7-21defca63268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4001, 4001, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s220m_20 = rasterio.open(s220m_20_fn).read().T\n",
    "s220m_20 = s220m_20[:, :, :-1] # Remove mask band for validation\n",
    "\n",
    "s220m_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4000, 4)\n",
      "(4000, 4000, 9)\n"
     ]
    }
   ],
   "source": [
    "encoded = ku.to_categorical(dove10_orbits, dtype='uint16')\n",
    "print(encoded.shape)\n",
    "\n",
    "dove10_with_orb = np.concatenate((dove10, encoded),axis=-1)\n",
    "print(dove10_with_orb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking image  1\n",
      "Shape is good:  (1000, 1000, 5)\n",
      "Checking image  2\n",
      "Shape is good:  (500, 500, 7)\n",
      "Checking image  3\n",
      "Shape is good:  (4000, 4000, 9)\n",
      "Checking image  4\n",
      "Shape is good:  (4001, 4001, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check for shape symetry and pad with zeros as needed\n",
    "model_images = [s210m_40, s220m_80, dove10_with_orb, s220m_20]\n",
    "\n",
    "for num, img in enumerate(model_images):   \n",
    "    print('Checking image ', num+1)    \n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        if img.shape[0] - img.shape[1] <= 3 and img.shape[0] - img.shape[1] > 0:\n",
    "            factor = img.shape[0] - img.shape[1]\n",
    "            print('%s more pixels in height' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, 0), (0, factor), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "        elif img.shape[1] - img.shape[0] <= 3 and img.shape[1] - img.shape[0] > 0:\n",
    "            factor = img.shape[1] - img.shape[0]        \n",
    "            print('%s more pixels in width' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, factor), (0, 0), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "    else:\n",
    "        print('Shape is good: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for compatibility among images\n",
    "mod_res_compare_size = model_images[0].shape[0]*4\n",
    "\n",
    "if model_images[2].shape[0] < mod_res_compare_size:\n",
    "    print('Fixing size compatibility. ')\n",
    "    diff = mod_res_compare_size - model_images[2].shape[0]\n",
    "    if diff < 5:\n",
    "        model_images[2] = np.pad(model_images[2], ((0, 0), (0, diff), (0, 0)))\n",
    "        model_images[2] = np.pad(model_images[2], ((0, diff), (0, 0), (0, 0)))\n",
    "        print('Padded with zeros. New shape: ', model_images[2].shape)\n",
    "    else:\n",
    "        print('Image size compatibility error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1635428111214,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "SiuRB6K6eI5R"
   },
   "outputs": [],
   "source": [
    "def get_test_patches(dset_10m, dset_20m, ps, dset_20gt, patchSize=24, border=4, ps_patch=96, ps_border=16):\n",
    "\n",
    "    PATCH_SIZE_HR = (patchSize, patchSize)\n",
    "    PATCH_SIZE_LR = [p//2 for p in PATCH_SIZE_HR]\n",
    "    BORDER_HR = border\n",
    "    BORDER_LR = BORDER_HR//2\n",
    "    PATCH_SIZE_PS = (ps_patch, ps_patch)\n",
    "    PATCH_SIZE_GT = (ps_patch-2*ps_border, ps_patch-2*ps_border)\n",
    "    \n",
    "    # Mirror the data at the borders to have the same dimensions as the input\n",
    "    dset_10 = np.pad(dset_10m, ((BORDER_HR, BORDER_HR), (BORDER_HR, BORDER_HR), (0, 0)))\n",
    "    dset_20 = np.pad(dset_20m, ((BORDER_LR, BORDER_LR), (BORDER_LR, BORDER_LR), (0, 0)))\n",
    "    dset_ps = np.pad(ps, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    dset_gt = np.pad(dset_20gt, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    \n",
    "    BANDS10 = dset_10.shape[2]\n",
    "    BANDS20 = dset_20.shape[2]\n",
    "    BANDSps = dset_ps.shape[2]\n",
    "    BANDSgt = dset_gt.shape[2]\n",
    "    patchesAlongi = (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    patchesAlongj = (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    nr_patches = (patchesAlongi + 1) * (patchesAlongj + 1)\n",
    "\n",
    "    label_20 = np.zeros((nr_patches, BANDSgt) + PATCH_SIZE_GT).astype(np.float32)   #initialize with PATCH_SIZE_PS but crop to PATCH_SIZE_GT\n",
    "    image_20 = np.zeros((nr_patches, BANDS20) + tuple(PATCH_SIZE_LR)).astype(np.float32)\n",
    "    image_10 = np.zeros((nr_patches, BANDS10) + PATCH_SIZE_HR).astype(np.float32)\n",
    "    image_ps = np.zeros((nr_patches, BANDSps) + PATCH_SIZE_PS).astype(np.float32)\n",
    "\n",
    "    range_i = np.arange(0, (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    range_j = np.arange(0, (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    if not (np.mod(dset_20.shape[0] - 2 * BORDER_LR, PATCH_SIZE_LR[0] - 2 * BORDER_LR) == 0):\n",
    "        range_i = np.append(range_i, (dset_20.shape[0] - PATCH_SIZE_LR[0]))\n",
    "    if not (np.mod(dset_20.shape[1] - 2 * BORDER_LR, PATCH_SIZE_LR[1] - 2 * BORDER_LR) == 0):\n",
    "        range_j = np.append(range_j, (dset_20.shape[1] - PATCH_SIZE_LR[1]))\n",
    "\n",
    "    pCount = 0\n",
    "    for ii in range_i.astype(int):\n",
    "        for jj in range_j.astype(int):\n",
    "            upper_left_i = ii\n",
    "            upper_left_j = jj\n",
    "            crop_point_lr = [upper_left_i,\n",
    "                             upper_left_j,\n",
    "                             upper_left_i + PATCH_SIZE_LR[0],\n",
    "                             upper_left_j + PATCH_SIZE_LR[1]]\n",
    "            crop_point_hr = [p*2 for p in crop_point_lr]\n",
    "            crop_point_ps = [p*4 for p in crop_point_hr]\n",
    "            crop_point_gt = [p*4 for p in crop_point_hr]\n",
    "\n",
    "            \n",
    "            label_20[pCount] = np.rollaxis(dset_gt[crop_point_gt[0]+ps_border:crop_point_gt[2]-ps_border, \n",
    "                                                crop_point_gt[1]+ps_border:crop_point_gt[3]-ps_border], 2)\n",
    "            \n",
    "            image_20[pCount] = np.rollaxis(dset_20[crop_point_lr[0]:crop_point_lr[2],\n",
    "                             crop_point_lr[1]:crop_point_lr[3]], 2)\n",
    "            \n",
    "            image_10[pCount] = np.rollaxis(dset_10[crop_point_hr[0]:crop_point_hr[2],\n",
    "                             crop_point_hr[1]:crop_point_hr[3]], 2)\n",
    "            \n",
    "            image_ps[pCount] = np.rollaxis(dset_ps[crop_point_ps[0]:crop_point_ps[2],\n",
    "                             crop_point_ps[1]:crop_point_ps[3]], 2)\n",
    "            pCount += 1\n",
    "\n",
    "    return image_10, image_20, image_ps, label_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4205,
     "status": "ok",
     "timestamp": 1635428115415,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "2DclF1KceMrS",
    "outputId": "265613c7-b5d8-4a1a-b1b7-5a71673e5751"
   },
   "outputs": [],
   "source": [
    "images_210, images_220, images_ps, label_20 = get_test_patches(model_images[0], model_images[1], model_images[2], model_images[3])\n",
    "#images_210, images_220, images_ps, label_20 = get_test_patches(s210m_40, s220m_80, dove10_with_orb, s220m_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1635428116386,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "s94kbHRwePXH",
    "outputId": "ce1b7b5e-ec98-48a9-8d2d-f36b76df9a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 24, 24, 5)\n",
      "(3969, 12, 12, 7)\n",
      "(3969, 96, 96, 9)\n",
      "(3969, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "images_210 = np.moveaxis(images_210, 1, 3)\n",
    "images_220 = np.moveaxis(images_220, 1, 3)\n",
    "images_ps = np.moveaxis(images_ps, 1, 3)\n",
    "label_20 = np.moveaxis(label_20, 1, 3)\n",
    "\n",
    "print(images_210.shape)\n",
    "print(images_220.shape)\n",
    "print(images_ps.shape)\n",
    "print(label_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2097,
     "status": "ok",
     "timestamp": 1635428119401,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "eokpDUcOeaQ6"
   },
   "outputs": [],
   "source": [
    "images_210_tr1, images_210_test, images_220_tr1, images_220_test, images_ps_tr1, images_ps_test, label_20_tr1, label_20_test = train_test_split(images_210, images_220, images_ps, label_20, test_size=0.1, random_state=1)\n",
    "images_210_train, images_210_val, images_220_train, images_220_val, images_ps_train, images_ps_val, label_20_train, label_20_val = train_test_split(images_210_tr1, images_220_tr1, images_ps_tr1, label_20_tr1, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fzts5DOledmK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 96, 96, 9)\n",
      "(3969, 24, 24, 5)\n",
      "(3969, 12, 12, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:23.344548: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-14 13:10:23.345059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-14 13:10:23.392754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.393000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-12-14 13:10:23.393019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 13:10:23.393879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 13:10:23.393911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-14 13:10:23.394749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-14 13:10:23.394898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-14 13:10:23.395772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-14 13:10:23.396198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-14 13:10:23.397928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 13:10:23.398004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.398283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.398496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-14 13:10:23.398913: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-14 13:10:23.399310: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-14 13:10:23.399372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.399599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-12-14 13:10:23.399617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 13:10:23.399633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 13:10:23.399648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-14 13:10:23.399663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-14 13:10:23.399677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-14 13:10:23.399691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-14 13:10:23.399714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-14 13:10:23.399729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 13:10:23.399811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.400060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.400269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-14 13:10:23.400292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-14 13:10:23.743477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-14 13:10:23.743497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-14 13:10:23.743501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-14 13:10:23.743657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.743976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.744209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-14 13:10:23.744417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6955 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S220c shape is (None, 12, 12, 2240)\n",
      "S220s shape is (None, 96, 96, 35)\n",
      "S210c shape is (None, 24, 24, 400)\n",
      "S210s shape is (None, 96, 96, 25)\n",
      "all_inp shape is (None, 96, 96, 69)\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_2/add:0', description=\"created by layer 'add_2'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_3/add:0', description=\"created by layer 'add_3'\")\n",
      "BofRDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='rdb_out/BiasAdd:0', description=\"created by layer 'rdb_out'\")\n",
      "Cropping KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 128), dtype=tf.float32, name=None), name='cropping2d/strided_slice:0', description=\"created by layer 'cropping2d'\")\n",
      "Output KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 4), dtype=tf.float32, name=None), name='conv2d_5/BiasAdd:0', description=\"created by layer 'conv2d_5'\")\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:23.913721: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-14 13:10:23.913742: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-14 13:10:23.913756: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2021-12-14 13:10:23.914196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2021-12-14 13:10:23.990344: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-14 13:10:23.990443: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "batch_size1 = 32\n",
    "epochs1 = 100\n",
    "steps_per_epoch = 300\n",
    "tryout = 200\n",
    "gpu = 16 #check\n",
    "sample = 32\n",
    "mlt = 5\n",
    "scale = 4\n",
    "# patch_size = int(scale * 1024)\n",
    "patch_size = 96\n",
    "\n",
    "test_only = False\n",
    "\n",
    "chk = 1\n",
    "CHANNEL = 3\n",
    "\n",
    "def shLoss(y_true, y_pred, delta=2.0):\n",
    "    diff = y_true-y_pred\n",
    "    dsq = tf.keras.backend.square(delta)\n",
    "    return tf.keras.backend.mean( dsq * (tf.sqrt(1+ tf.square(diff)/dsq)-1), axis=-1)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "        return 10* k.log(255**2 /(k.mean(k.square(y_pred - y_true))))\n",
    "\n",
    "\n",
    "class SRResnet:\n",
    "    def L1_loss(self , y_true , y_pred):\n",
    "        return k.mean(k.abs(y_true - y_pred))\n",
    "    \n",
    "    def RDBlocks(self, x, name, count = 6, filter_count=32, RDB_feat=64):\n",
    "        ## 6 layers of RDB block\n",
    "        ## this thing need to be in a damn loop for more customisability\n",
    "        li = [x]\n",
    "        pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu' , name = name+'_conv1')(x)\n",
    "\n",
    "        for i in range(2 , count+1):\n",
    "            li.append(pas)\n",
    "            out =  Concatenate(axis = -1)(li) # conctenated output self.channel_axis\n",
    "            pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu', name = name+'_conv'+str(i))(out)\n",
    "\n",
    "        li.append(pas)\n",
    "        out1 = Concatenate(axis = -1)(li) #self.channel_axis\n",
    "        feat = Convolution2D(filters=RDB_feat, kernel_size=(1,1), strides=(1, 1), padding='same',activation='relu' , name = name+'_Local_Conv')(out1)\n",
    "\n",
    "        feat = Add()([feat , x])\n",
    "        print(\"RDBlocks\",feat)\n",
    "        return feat\n",
    "        \n",
    "    def visualize(self):\n",
    "        plot_model(self.model, to_file='model.png' , show_shapes = True)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def Block_Of_RDBBlocks(self, inp, RDB_count=20, count=6, filter_count=32, RDB_feat=64, end_feat=64):\n",
    "        \n",
    "        pass1 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(inp)\n",
    "\n",
    "        pass2 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pass1)\n",
    "\n",
    "\n",
    "        RDB = self.RDBlocks(pass2 , 'RDB1', count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "        RDBlocks_list = [RDB,]\n",
    "        for i in range(2,RDB_count+1):\n",
    "            RDB = self.RDBlocks(RDB ,'RDB'+str(i), count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "            RDBlocks_list.append(RDB)\n",
    "        out = Concatenate(axis = -1)(RDBlocks_list) #self.channel_axis\n",
    "        out = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(out)\n",
    "        output = Add()([out, pass1])\n",
    "        output = Convolution2D(filters=end_feat, kernel_size=(3,3), strides=(1,1), padding='same', name=\"rdb_out\")(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __init__(self, s10img, s20img, psimg, lr=0.00005, patch_size=32, RDB_count=4, count=2, filter_count=64, RDB_feat=128, end_feat=128, chk = -1, scale = 4):\n",
    "        self.channel_axis = 3\n",
    "        inp10 = Input(shape = (s10img.shape[1], s10img.shape[2], s10img.shape[3]))   # (24,24,4)\n",
    "        inp20 = Input(shape = (s20img.shape[1], s20img.shape[2], s20img.shape[3]))   # (12,12,6)\n",
    "        inpPS = Input(shape = (psimg.shape[1], psimg.shape[2], psimg.shape[3]))   # (96,96,9)\n",
    "        print(psimg.shape)\n",
    "        print(s10img.shape)\n",
    "        print(s20img.shape)\n",
    "#         print(psorb.shape)\n",
    "#         ps = tf.keras.layers.Concatenate(axis=2)([psimg, psorb])\n",
    "\n",
    "        Subpixel_scale8 = Lambda(lambda x:tf.nn.depth_to_space(x,8))\n",
    "        Subpixel_scale4 = Lambda(lambda x:tf.nn.depth_to_space(x,4))\n",
    "        \n",
    "        s220c = Convolution2D(filters = (s20img.shape[3])*8*8*mlt, kernel_size=1, strides=1, padding='valid')(inp20)\n",
    "        print(\"S220c shape is\", s220c.shape)\n",
    "        s220s = Subpixel_scale8(inputs=s220c)\n",
    "        print(\"S220s shape is\", s220s.shape)\n",
    "        m20 = Model(inputs=inp20, outputs=s220s)\n",
    "        s210c = Convolution2D(filters = (s10img.shape[3])*4*4*mlt, kernel_size=1, strides=1, padding='valid')(inp10)\n",
    "        print(\"S210c shape is\", s210c.shape)\n",
    "        s210s = Subpixel_scale4(inputs=s210c)\n",
    "        print(\"S210s shape is\", s210s.shape)\n",
    "        m10 = Model(inputs=inp10, outputs=s210s)\n",
    "        \n",
    "        all_inp = Concatenate(axis=-1)([m10.output, m20.output, inpPS])\n",
    "        print(\"all_inp shape is\", all_inp.shape)\n",
    "        allb = self.Block_Of_RDBBlocks(all_inp, RDB_count, count, filter_count, RDB_feat, end_feat)\n",
    "        print(\"BofRDBlocks\",allb)\n",
    "        allm = Cropping2D(cropping=16)(allb)\n",
    "        print(\"Cropping\",allm)\n",
    "        allrc = Convolution2D(filters = 4, kernel_size = 1, strides = 1, padding = \"valid\", activation = None)(allm)\n",
    "        \n",
    "        print(\"Output\", allrc)\n",
    "        model = Model(inputs=[m10.input, m20.input, inpPS], outputs = allrc)\n",
    "#         print([n.input_tensors.name for n in model.get_layer('A_3').inbound_nodes])\n",
    "        adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=0, amsgrad=False)\n",
    "\n",
    "        model.compile(loss=shLoss, optimizer='adam' , metrics=['mae'])\n",
    "\n",
    "        if chk >=0 :\n",
    "            print(\"loading existing weights !!!\")\n",
    "            model.load_weights('final.h5')\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "    def fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, steps_per_epoch):   \n",
    "        hist = self.model.fit(x, y, batch_size, epochs, verbose, callbacks, validation_data=validation_data, steps_per_epoch=steps_per_epoch)\n",
    "        return hist.history\n",
    "\n",
    "\n",
    "chk = -1\n",
    "net = SRResnet(images_210, images_220, images_ps, lr = lr ,scale = scale , chk = chk)\n",
    "net.visualize()\n",
    "# net.get_model().summary()\n",
    "\n",
    "my_callbacks =[\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath='model4x.{epoch:02d}-{val_loss:.2f}',\n",
    "              monitor = \"loss\",\n",
    "              verbose = 1,\n",
    "              save_best_only = True,\n",
    "              save_freq = \"epoch\"\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "              monitor = \"loss\",\n",
    "              factor = 0.9,\n",
    "              patience = 20,\n",
    "              verbose = 1,\n",
    "              min_lr = 0.0001 / 10\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "              monitor = \"loss\",\n",
    "              min_delta = 2,\n",
    "              patience = 200,\n",
    "              verbose = 1,\n",
    "              baseline = None,\n",
    "              restore_best_weights = False\n",
    "            ),\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 24, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12, 12, 7)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 400)  2400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 12, 12, 2240) 17920       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 96, 96, 25)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 96, 96, 35)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 96, 96, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96, 96, 69)   0           lambda_1[0][0]                   \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 128)  79616       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_conv1 (Conv2D)             (None, 96, 96, 64)   73792       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 192)  0           conv2d_3[0][0]                   \n",
      "                                                                 RDB1_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 RDB1_conv1[0][0]                 \n",
      "                                                                 RDB1_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB1_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 96, 96, 128)  0           RDB1_Local_Conv[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 96, 96, 192)  0           add[0][0]                        \n",
      "                                                                 RDB2_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 256)  0           add[0][0]                        \n",
      "                                                                 RDB2_conv1[0][0]                 \n",
      "                                                                 RDB2_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB2_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 96, 96, 128)  0           RDB2_Local_Conv[0][0]            \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 96, 96, 192)  0           add_1[0][0]                      \n",
      "                                                                 RDB3_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 96, 256)  0           add_1[0][0]                      \n",
      "                                                                 RDB3_conv1[0][0]                 \n",
      "                                                                 RDB3_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB3_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 96, 96, 128)  0           RDB3_Local_Conv[0][0]            \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_conv1 (Conv2D)             (None, 96, 96, 64)   73792       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96, 96, 192)  0           add_2[0][0]                      \n",
      "                                                                 RDB4_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_conv2 (Conv2D)             (None, 96, 96, 64)   110656      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96, 96, 256)  0           add_2[0][0]                      \n",
      "                                                                 RDB4_conv1[0][0]                 \n",
      "                                                                 RDB4_conv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RDB4_Local_Conv (Conv2D)        (None, 96, 96, 128)  32896       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 96, 96, 128)  0           RDB4_Local_Conv[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 96, 96, 512)  0           add[0][0]                        \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 96, 128)  589952      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 96, 96, 128)  0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rdb_out (Conv2D)                (None, 96, 96, 128)  147584      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 64, 64, 128)  0           rdb_out[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 4)    516         cropping2d[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,854,948\n",
      "Trainable params: 1,854,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1be614078f7f6aa6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1be614078f7f6aa6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:25.831546: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1066328064 exceeds 10% of free system memory.\n",
      "2021-12-14 13:10:26.338070: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-14 13:10:26.355861: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:27.072694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-14 13:10:27.805917: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-14 13:10:27.860454: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-12-14 13:10:28.363437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-14 13:10:34.339764: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 13:10:36.352340: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 13:10:36.871161: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 13:10:38.514705: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-14 13:10:40.262940: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.79GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/101 [..............................] - ETA: 30:23 - loss: 28145.6348 - mae: 14074.8164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:44.620865: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-14 13:10:44.620885: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/101 [..............................] - ETA: 40s - loss: 116716.0908 - mae: 58360.0449 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:10:45.015370: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-14 13:10:45.015830: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2021-12-14 13:10:45.018275: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 495 callback api events and 483 activity events. \n",
      "2021-12-14 13:10:45.032655: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-14 13:10:45.039210: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_14_13_10_45\n",
      "2021-12-14 13:10:45.044365: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.trace.json.gz\n",
      "2021-12-14 13:10:45.061547: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_14_13_10_45\n",
      "2021-12-14 13:10:45.064007: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.memory_profile.json.gz\n",
      "2021-12-14 13:10:45.064604: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_14_13_10_45Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_14_13_10_45/pop-os.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 84s 658ms/step - loss: 25157.0200 - mae: 12580.5010 - val_loss: 1885.1635 - val_mae: 944.5728\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8247.83984, saving model to model4x.01-1885.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:11:50.883357: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model4x.01-1885.16/assets\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 42s 414ms/step - loss: 1758.1616 - mae: 881.0665 - val_loss: 2281.0315 - val_mae: 1142.5077\n",
      "\n",
      "Epoch 00002: loss improved from 8247.83984 to 1776.94165, saving model to model4x.02-2281.03\n",
      "INFO:tensorflow:Assets written to: model4x.02-2281.03/assets\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 1883.2359 - mae: 943.6072 - val_loss: 1561.9922 - val_mae: 782.9833\n",
      "\n",
      "Epoch 00003: loss did not improve from 1776.94165\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 44s 435ms/step - loss: 1350.2892 - mae: 677.1248 - val_loss: 1458.6003 - val_mae: 731.2890\n",
      "\n",
      "Epoch 00004: loss improved from 1776.94165 to 1370.83630, saving model to model4x.04-1458.60\n",
      "INFO:tensorflow:Assets written to: model4x.04-1458.60/assets\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 44s 435ms/step - loss: 1269.4587 - mae: 636.7095 - val_loss: 1127.6481 - val_mae: 565.8041\n",
      "\n",
      "Epoch 00005: loss improved from 1370.83630 to 1282.57788, saving model to model4x.05-1127.65\n",
      "INFO:tensorflow:Assets written to: model4x.05-1127.65/assets\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 44s 436ms/step - loss: 1507.9989 - mae: 755.9846 - val_loss: 2353.9551 - val_mae: 1178.9736\n",
      "\n",
      "Epoch 00006: loss did not improve from 1282.57788\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1726.3207 - mae: 865.1490 - val_loss: 1184.5884 - val_mae: 594.2737\n",
      "\n",
      "Epoch 00007: loss did not improve from 1282.57788\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 44s 436ms/step - loss: 1365.7150 - mae: 684.8406 - val_loss: 1563.6742 - val_mae: 783.8287\n",
      "\n",
      "Epoch 00008: loss did not improve from 1282.57788\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1408.8755 - mae: 706.4225 - val_loss: 965.2142 - val_mae: 484.5817\n",
      "\n",
      "Epoch 00009: loss improved from 1282.57788 to 1247.54309, saving model to model4x.09-965.21\n",
      "INFO:tensorflow:Assets written to: model4x.09-965.21/assets\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1060.3146 - mae: 532.1341 - val_loss: 1063.7069 - val_mae: 533.8328\n",
      "\n",
      "Epoch 00010: loss improved from 1247.54309 to 1179.51135, saving model to model4x.10-1063.71\n",
      "INFO:tensorflow:Assets written to: model4x.10-1063.71/assets\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1266.1381 - mae: 635.0507 - val_loss: 1525.4886 - val_mae: 764.7362\n",
      "\n",
      "Epoch 00011: loss did not improve from 1179.51135\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 44s 439ms/step - loss: 1443.8680 - mae: 723.9211 - val_loss: 937.9894 - val_mae: 470.9632\n",
      "\n",
      "Epoch 00012: loss did not improve from 1179.51135\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 944.3118 - mae: 474.1281 - val_loss: 1335.7372 - val_mae: 669.8570\n",
      "\n",
      "Epoch 00013: loss improved from 1179.51135 to 947.91345, saving model to model4x.13-1335.74\n",
      "INFO:tensorflow:Assets written to: model4x.13-1335.74/assets\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 44s 436ms/step - loss: 1153.4693 - mae: 578.7146 - val_loss: 986.0788 - val_mae: 495.0175\n",
      "\n",
      "Epoch 00014: loss did not improve from 947.91345\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1044.2574 - mae: 524.1069 - val_loss: 959.0229 - val_mae: 481.4864\n",
      "\n",
      "Epoch 00015: loss did not improve from 947.91345\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1080.4388 - mae: 542.1993 - val_loss: 1135.1520 - val_mae: 569.5558\n",
      "\n",
      "Epoch 00016: loss did not improve from 947.91345\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1069.0157 - mae: 536.4866 - val_loss: 2184.7766 - val_mae: 1094.3838\n",
      "\n",
      "Epoch 00017: loss did not improve from 947.91345\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 44s 437ms/step - loss: 1010.5769 - mae: 507.2644 - val_loss: 1044.8776 - val_mae: 524.4165\n",
      "\n",
      "Epoch 00018: loss improved from 947.91345 to 905.91467, saving model to model4x.18-1044.88\n",
      "INFO:tensorflow:Assets written to: model4x.18-1044.88/assets\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 44s 441ms/step - loss: 964.3647 - mae: 484.1577 - val_loss: 994.9709 - val_mae: 499.4697\n",
      "\n",
      "Epoch 00019: loss did not improve from 905.91467\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 1186.7551 - mae: 595.3590 - val_loss: 1141.4790 - val_mae: 572.7169\n",
      "\n",
      "Epoch 00020: loss did not improve from 905.91467\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 1445.3607 - mae: 724.6695 - val_loss: 1306.2164 - val_mae: 655.0933\n",
      "\n",
      "Epoch 00021: loss did not improve from 905.91467\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 1059.3870 - mae: 531.6728 - val_loss: 761.8231 - val_mae: 382.8817\n",
      "\n",
      "Epoch 00022: loss did not improve from 905.91467\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 760.5791 - mae: 382.2590 - val_loss: 747.0189 - val_mae: 375.4784\n",
      "\n",
      "Epoch 00023: loss improved from 905.91467 to 775.31152, saving model to model4x.23-747.02\n",
      "INFO:tensorflow:Assets written to: model4x.23-747.02/assets\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 925.4929 - mae: 464.7218 - val_loss: 808.6063 - val_mae: 406.2743\n",
      "\n",
      "Epoch 00024: loss did not improve from 775.31152\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 753.7248 - mae: 378.8320 - val_loss: 762.2277 - val_mae: 383.0898\n",
      "\n",
      "Epoch 00025: loss improved from 775.31152 to 765.88696, saving model to model4x.25-762.23\n",
      "INFO:tensorflow:Assets written to: model4x.25-762.23/assets\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 747.9006 - mae: 375.9199 - val_loss: 709.0245 - val_mae: 356.4812\n",
      "\n",
      "Epoch 00026: loss improved from 765.88696 to 759.30780, saving model to model4x.26-709.02\n",
      "INFO:tensorflow:Assets written to: model4x.26-709.02/assets\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 821.5750 - mae: 412.7603 - val_loss: 742.2725 - val_mae: 373.1080\n",
      "\n",
      "Epoch 00027: loss did not improve from 759.30780\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 990.3960 - mae: 497.1754 - val_loss: 1064.8296 - val_mae: 534.4014\n",
      "\n",
      "Epoch 00028: loss did not improve from 759.30780\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 992.5263 - mae: 498.2429 - val_loss: 708.9928 - val_mae: 356.4619\n",
      "\n",
      "Epoch 00029: loss did not improve from 759.30780\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 865.5101 - mae: 434.7300 - val_loss: 1088.0222 - val_mae: 545.9957\n",
      "\n",
      "Epoch 00030: loss did not improve from 759.30780\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 963.3123 - mae: 483.6360 - val_loss: 767.4659 - val_mae: 385.7046\n",
      "\n",
      "Epoch 00031: loss did not improve from 759.30780\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 866.6533 - mae: 435.3018 - val_loss: 667.4611 - val_mae: 335.6954\n",
      "\n",
      "Epoch 00032: loss did not improve from 759.30780\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 704.2135 - mae: 354.0747 - val_loss: 799.1369 - val_mae: 401.5495\n",
      "\n",
      "Epoch 00033: loss improved from 759.30780 to 697.68109, saving model to model4x.33-799.14\n",
      "INFO:tensorflow:Assets written to: model4x.33-799.14/assets\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 710.9952 - mae: 357.4664 - val_loss: 777.9499 - val_mae: 390.9510\n",
      "\n",
      "Epoch 00034: loss did not improve from 697.68109\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 703.7317 - mae: 353.8350 - val_loss: 1100.0863 - val_mae: 552.0316\n",
      "\n",
      "Epoch 00035: loss did not improve from 697.68109\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 946.2597 - mae: 475.1088 - val_loss: 1264.6206 - val_mae: 634.3015\n",
      "\n",
      "Epoch 00036: loss did not improve from 697.68109\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 1073.6357 - mae: 538.8014 - val_loss: 737.8458 - val_mae: 370.8898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: loss did not improve from 697.68109\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 688.8454 - mae: 346.3876 - val_loss: 861.1321 - val_mae: 432.5507\n",
      "\n",
      "Epoch 00038: loss improved from 697.68109 to 659.71826, saving model to model4x.38-861.13\n",
      "INFO:tensorflow:Assets written to: model4x.38-861.13/assets\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 737.8491 - mae: 370.8950 - val_loss: 631.5688 - val_mae: 317.7459\n",
      "\n",
      "Epoch 00039: loss did not improve from 659.71826\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 752.3413 - mae: 378.1413 - val_loss: 777.0784 - val_mae: 390.5155\n",
      "\n",
      "Epoch 00040: loss did not improve from 659.71826\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 945.1969 - mae: 474.5775 - val_loss: 643.9290 - val_mae: 323.9324\n",
      "\n",
      "Epoch 00041: loss did not improve from 659.71826\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 698.0915 - mae: 351.0134 - val_loss: 780.5670 - val_mae: 392.2573\n",
      "\n",
      "Epoch 00042: loss did not improve from 659.71826\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 920.8364 - mae: 462.3973 - val_loss: 644.3236 - val_mae: 324.1243\n",
      "\n",
      "Epoch 00043: loss did not improve from 659.71826\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 631.1719 - mae: 317.5481 - val_loss: 611.2735 - val_mae: 307.5978\n",
      "\n",
      "Epoch 00044: loss improved from 659.71826 to 612.43115, saving model to model4x.44-611.27\n",
      "INFO:tensorflow:Assets written to: model4x.44-611.27/assets\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 621.8163 - mae: 312.8719 - val_loss: 609.7960 - val_mae: 306.8599\n",
      "\n",
      "Epoch 00045: loss did not improve from 612.43115\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 44s 433ms/step - loss: 670.4937 - mae: 337.2116 - val_loss: 690.4772 - val_mae: 347.2079\n",
      "\n",
      "Epoch 00046: loss did not improve from 612.43115\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 807.3191 - mae: 405.6334 - val_loss: 610.4418 - val_mae: 307.1864\n",
      "\n",
      "Epoch 00047: loss did not improve from 612.43115\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 633.8132 - mae: 318.8709 - val_loss: 678.3811 - val_mae: 341.1652\n",
      "\n",
      "Epoch 00048: loss did not improve from 612.43115\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 44s 433ms/step - loss: 632.1798 - mae: 318.0547 - val_loss: 660.2224 - val_mae: 332.0732\n",
      "\n",
      "Epoch 00049: loss did not improve from 612.43115\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 44s 433ms/step - loss: 619.2141 - mae: 311.5713 - val_loss: 1118.9368 - val_mae: 561.4492\n",
      "\n",
      "Epoch 00050: loss did not improve from 612.43115\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 805.2005 - mae: 404.5730 - val_loss: 1316.7349 - val_mae: 660.3600\n",
      "\n",
      "Epoch 00051: loss did not improve from 612.43115\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 992.5241 - mae: 498.2436 - val_loss: 797.8407 - val_mae: 400.8979\n",
      "\n",
      "Epoch 00052: loss did not improve from 612.43115\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 677.8936 - mae: 340.9141 - val_loss: 603.0071 - val_mae: 303.4691\n",
      "\n",
      "Epoch 00053: loss did not improve from 612.43115\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 603.6224 - mae: 303.7755 - val_loss: 586.0670 - val_mae: 294.9939\n",
      "\n",
      "Epoch 00054: loss improved from 612.43115 to 592.94055, saving model to model4x.54-586.07\n",
      "INFO:tensorflow:Assets written to: model4x.54-586.07/assets\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 587.7815 - mae: 295.8521 - val_loss: 610.3276 - val_mae: 307.1339\n",
      "\n",
      "Epoch 00055: loss improved from 592.94055 to 591.75659, saving model to model4x.55-610.33\n",
      "INFO:tensorflow:Assets written to: model4x.55-610.33/assets\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 603.6372 - mae: 303.7820 - val_loss: 598.8989 - val_mae: 301.4114\n",
      "\n",
      "Epoch 00056: loss did not improve from 591.75659\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 647.6103 - mae: 325.7702 - val_loss: 550.9745 - val_mae: 277.4430\n",
      "\n",
      "Epoch 00057: loss did not improve from 591.75659\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 731.2157 - mae: 367.5774 - val_loss: 568.4095 - val_mae: 286.1631\n",
      "\n",
      "Epoch 00058: loss did not improve from 591.75659\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 44s 433ms/step - loss: 596.5826 - mae: 300.2555 - val_loss: 595.4030 - val_mae: 299.6654\n",
      "\n",
      "Epoch 00059: loss did not improve from 591.75659\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 591.0527 - mae: 297.4887 - val_loss: 608.2928 - val_mae: 306.1029\n",
      "\n",
      "Epoch 00060: loss improved from 591.75659 to 591.28326, saving model to model4x.60-608.29\n",
      "INFO:tensorflow:Assets written to: model4x.60-608.29/assets\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 623.2850 - mae: 313.6074 - val_loss: 635.3088 - val_mae: 319.6257\n",
      "\n",
      "Epoch 00061: loss did not improve from 591.28326\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 44s 432ms/step - loss: 608.9122 - mae: 306.4214 - val_loss: 582.5898 - val_mae: 293.2604\n",
      "\n",
      "Epoch 00062: loss did not improve from 591.28326\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 643.5694 - mae: 323.7520 - val_loss: 593.6163 - val_mae: 298.7696\n",
      "\n",
      "Epoch 00063: loss did not improve from 591.28326\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 745.9281 - mae: 374.9359 - val_loss: 563.1561 - val_mae: 283.5392\n",
      "\n",
      "Epoch 00064: loss did not improve from 591.28326\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 44s 431ms/step - loss: 576.7715 - mae: 290.3485 - val_loss: 561.6545 - val_mae: 282.7819\n",
      "\n",
      "Epoch 00065: loss improved from 591.28326 to 584.92450, saving model to model4x.65-561.65\n",
      "INFO:tensorflow:Assets written to: model4x.65-561.65/assets\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 632.7615 - mae: 318.3465 - val_loss: 770.5903 - val_mae: 387.2650\n",
      "\n",
      "Epoch 00066: loss did not improve from 584.92450\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 907.0546 - mae: 455.5092 - val_loss: 696.2722 - val_mae: 350.1129\n",
      "\n",
      "Epoch 00067: loss did not improve from 584.92450\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 692.7551 - mae: 348.3461 - val_loss: 600.4223 - val_mae: 302.1784\n",
      "\n",
      "Epoch 00068: loss did not improve from 584.92450\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 546.3564 - mae: 275.1376 - val_loss: 547.3288 - val_mae: 275.6202\n",
      "\n",
      "Epoch 00069: loss improved from 584.92450 to 546.14905, saving model to model4x.69-547.33\n",
      "INFO:tensorflow:Assets written to: model4x.69-547.33/assets\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 556.9731 - mae: 280.4460 - val_loss: 516.5767 - val_mae: 260.2434\n",
      "\n",
      "Epoch 00070: loss did not improve from 546.14905\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 586.3267 - mae: 295.1262 - val_loss: 536.7679 - val_mae: 270.3421\n",
      "\n",
      "Epoch 00071: loss did not improve from 546.14905\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 556.9138 - mae: 280.4171 - val_loss: 639.9774 - val_mae: 321.9494\n",
      "\n",
      "Epoch 00072: loss did not improve from 546.14905\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 560.3136 - mae: 282.1175 - val_loss: 552.0979 - val_mae: 278.0112\n",
      "\n",
      "Epoch 00073: loss did not improve from 546.14905\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 546.0515 - mae: 274.9862 - val_loss: 524.5752 - val_mae: 264.2396\n",
      "\n",
      "Epoch 00074: loss did not improve from 546.14905\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 585.9362 - mae: 294.9305 - val_loss: 595.5226 - val_mae: 299.7238\n",
      "\n",
      "Epoch 00075: loss did not improve from 546.14905\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 583.1259 - mae: 293.5260 - val_loss: 557.0572 - val_mae: 280.4861\n",
      "\n",
      "Epoch 00076: loss did not improve from 546.14905\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 562.6663 - mae: 283.2945 - val_loss: 546.8003 - val_mae: 275.3593\n",
      "\n",
      "Epoch 00077: loss did not improve from 546.14905\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 570.8993 - mae: 287.4120 - val_loss: 521.0334 - val_mae: 262.4689\n",
      "\n",
      "Epoch 00078: loss did not improve from 546.14905\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 551.8007 - mae: 277.8611 - val_loss: 639.8883 - val_mae: 321.9124\n",
      "\n",
      "Epoch 00079: loss did not improve from 546.14905\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 630.7564 - mae: 317.3450 - val_loss: 662.3437 - val_mae: 333.1347\n",
      "\n",
      "Epoch 00080: loss did not improve from 546.14905\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 789.1713 - mae: 396.5600 - val_loss: 610.8034 - val_mae: 307.3691\n",
      "\n",
      "Epoch 00081: loss did not improve from 546.14905\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 573.0371 - mae: 288.4818 - val_loss: 487.3171 - val_mae: 245.6058\n",
      "\n",
      "Epoch 00082: loss did not improve from 546.14905\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 543.6081 - mae: 273.7648 - val_loss: 705.8255 - val_mae: 354.8930\n",
      "\n",
      "Epoch 00083: loss did not improve from 546.14905\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 43s 429ms/step - loss: 554.4337 - mae: 279.1785 - val_loss: 503.8085 - val_mae: 253.8581\n",
      "\n",
      "Epoch 00084: loss improved from 546.14905 to 544.66138, saving model to model4x.84-503.81\n",
      "INFO:tensorflow:Assets written to: model4x.84-503.81/assets\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 525.3946 - mae: 264.6547 - val_loss: 605.7394 - val_mae: 304.8317\n",
      "\n",
      "Epoch 00085: loss improved from 544.66138 to 533.51697, saving model to model4x.85-605.74\n",
      "INFO:tensorflow:Assets written to: model4x.85-605.74/assets\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 43s 429ms/step - loss: 548.3639 - mae: 276.1428 - val_loss: 557.1424 - val_mae: 280.5313\n",
      "\n",
      "Epoch 00086: loss did not improve from 533.51697\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 534.4125 - mae: 269.1669 - val_loss: 584.4333 - val_mae: 294.1806\n",
      "\n",
      "Epoch 00087: loss did not improve from 533.51697\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 740.5008 - mae: 372.2237 - val_loss: 512.3948 - val_mae: 258.1539\n",
      "\n",
      "Epoch 00088: loss did not improve from 533.51697\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 515.4281 - mae: 259.6723 - val_loss: 537.4360 - val_mae: 270.6713\n",
      "\n",
      "Epoch 00089: loss did not improve from 533.51697\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 43s 429ms/step - loss: 542.7965 - mae: 273.3572 - val_loss: 816.9573 - val_mae: 410.4588\n",
      "\n",
      "Epoch 00090: loss did not improve from 533.51697\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 644.7699 - mae: 324.3521 - val_loss: 533.8743 - val_mae: 268.8962\n",
      "\n",
      "Epoch 00091: loss did not improve from 533.51697\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 43s 429ms/step - loss: 534.6121 - mae: 269.2662 - val_loss: 544.6984 - val_mae: 274.3139\n",
      "\n",
      "Epoch 00092: loss improved from 533.51697 to 531.79028, saving model to model4x.92-544.70\n",
      "INFO:tensorflow:Assets written to: model4x.92-544.70/assets\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 604.7053 - mae: 304.3183 - val_loss: 531.7338 - val_mae: 267.8270\n",
      "\n",
      "Epoch 00093: loss did not improve from 531.79028\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 523.8066 - mae: 263.8633 - val_loss: 544.4002 - val_mae: 274.1604\n",
      "\n",
      "Epoch 00094: loss did not improve from 531.79028\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 541.7719 - mae: 272.8456 - val_loss: 538.6882 - val_mae: 271.2989\n",
      "\n",
      "Epoch 00095: loss did not improve from 531.79028\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 532.9280 - mae: 268.4231 - val_loss: 644.9222 - val_mae: 324.4354\n",
      "\n",
      "Epoch 00096: loss did not improve from 531.79028\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 534.1456 - mae: 269.0314 - val_loss: 565.5438 - val_mae: 284.7346\n",
      "\n",
      "Epoch 00097: loss did not improve from 531.79028\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 564.7456 - mae: 284.3341 - val_loss: 496.9438 - val_mae: 250.4225\n",
      "\n",
      "Epoch 00098: loss did not improve from 531.79028\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 43s 431ms/step - loss: 538.8039 - mae: 271.3627 - val_loss: 591.3023 - val_mae: 297.6197\n",
      "\n",
      "Epoch 00099: loss did not improve from 531.79028\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 43s 430ms/step - loss: 527.2175 - mae: 265.5692 - val_loss: 490.1962 - val_mae: 247.0478\n",
      "\n",
      "Epoch 00100: loss improved from 531.79028 to 523.21149, saving model to model4x.100-490.20\n",
      "INFO:tensorflow:Assets written to: model4x.100-490.20/assets\n",
      "INFO:tensorflow:Assets written to: /home/sarahwegmueller/Documents/Casden_dev/Lakewood_OW/TimeSeries/finals/17Jun21_trained_4x_model/assets\n"
     ]
    }
   ],
   "source": [
    "model10 = net.get_model()\n",
    "model10.summary()\n",
    "%tensorboard --logdir logs/\n",
    "model10.fit(x=[images_210_train, images_220_train, images_ps_train], y=label_20_train, batch_size=batch_size1, epochs=epochs1, verbose=1, callbacks=my_callbacks, validation_data=([images_210_val, images_220_val, images_ps_val], label_20_val))#, validation_steps = 3) #steps_per_epoch=steps_per_epoch\n",
    "\n",
    "model10.save(output_folder + date + 'trained_10m_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gSJOnNzQm55S"
   },
   "outputs": [],
   "source": [
    "# Remove old models and log files\n",
    "files_list = os.listdir()\n",
    "\n",
    "for file in files_list:\n",
    "    if 'model' in file:\n",
    "        shutil.rmtree(file)\n",
    "        \n",
    "for file in files_list:\n",
    "    if 'logs' in file:\n",
    "        shutil.rmtree(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SuperResTraining4x.ipynb",
   "provenance": [
    {
     "file_id": "1SLGUAH7f6cTH7WMEFnOSuL3LxtMlHVdJ",
     "timestamp": 1634931909576
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
